{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ba672df",
   "metadata": {},
   "source": [
    "# Trainingspipeline 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bb0ffc",
   "metadata": {},
   "source": [
    "- ohne Bigramme\n",
    "- vector_size: 300\n",
    "- window: 5\n",
    "- min_count: 1\n",
    "- seed: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08e5260c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import nltk\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import scipy\n",
    "import spacy\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from joblib import Parallel, delayed  \n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09922b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stopwords.words('italian')\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/italian.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73f800bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ad', 'al', 'allo', 'ai', 'agli', 'all', 'agl', 'alla', 'alle', 'con', 'col', 'coi', 'da', 'dal', 'dallo', 'dai', 'dagli', 'dall', 'dagl', 'dalla', 'dalle', 'di', 'del', 'dello', 'dei', 'degli', 'dell', 'degl', 'della', 'delle', 'in', 'nel', 'nello', 'nei', 'negli', 'nell', 'negl', 'nella', 'nelle', 'su', 'sul', 'sullo', 'sui', 'sugli', 'sull', 'sugl', 'sulla', 'sulle', 'per', 'tra', 'contro', 'io', 'tu', 'lui', 'lei', 'noi', 'voi', 'loro', 'mio', 'mia', 'miei', 'mie', 'tuo', 'tua', 'tuoi', 'tue', 'suo', 'sua', 'suoi', 'sue', 'nostro', 'nostra', 'nostri', 'nostre', 'vostro', 'vostra', 'vostri', 'vostre', 'mi', 'ti', 'ci', 'vi', 'lo', 'la', 'li', 'le', 'gli', 'ne', 'il', 'un', 'uno', 'una', 'ma', 'ed', 'se', 'perché', 'anche', 'come', 'dov', 'dove', 'che', 'chi', 'cui', 'non', 'più', 'quale', 'quanto', 'quanti', 'quanta', 'quante', 'quello', 'quelli', 'quella', 'quelle', 'questo', 'questi', 'questa', 'queste', 'si', 'tutto', 'tutti', 'a', 'c', 'e', 'i', 'l', 'o', 'ho', 'hai', 'ha', 'abbiamo', 'avete', 'hanno', 'abbia', 'abbiate', 'abbiano', 'avrò', 'avrai', 'avrà', 'avremo', 'avrete', 'avranno', 'avrei', 'avresti', 'avrebbe', 'avremmo', 'avreste', 'avrebbero', 'avevo', 'avevi', 'aveva', 'avevamo', 'avevate', 'avevano', 'ebbi', 'avesti', 'ebbe', 'avemmo', 'aveste', 'ebbero', 'avessi', 'avesse', 'avessimo', 'avessero', 'avendo', 'avuto', 'avuta', 'avuti', 'avute', 'sono', 'sei', 'è', 'siamo', 'siete', 'sia', 'siate', 'siano', 'sarò', 'sarai', 'sarà', 'saremo', 'sarete', 'saranno', 'sarei', 'saresti', 'sarebbe', 'saremmo', 'sareste', 'sarebbero', 'ero', 'eri', 'era', 'eravamo', 'eravate', 'erano', 'fui', 'fosti', 'fu', 'fummo', 'foste', 'furono', 'fossi', 'fosse', 'fossimo', 'fossero', 'essendo', 'faccio', 'fai', 'facciamo', 'fanno', 'faccia', 'facciate', 'facciano', 'farò', 'farai', 'farà', 'faremo', 'farete', 'faranno', 'farei', 'faresti', 'farebbe', 'faremmo', 'fareste', 'farebbero', 'facevo', 'facevi', 'faceva', 'facevamo', 'facevate', 'facevano', 'feci', 'facesti', 'fece', 'facemmo', 'faceste', 'fecero', 'facessi', 'facesse', 'facessimo', 'facessero', 'facendo', 'sto', 'stai', 'sta', 'stiamo', 'stanno', 'stia', 'stiate', 'stiano', 'starò', 'starai', 'starà', 'staremo', 'starete', 'staranno', 'starei', 'staresti', 'starebbe', 'staremmo', 'stareste', 'starebbero', 'stavo', 'stavi', 'stava', 'stavamo', 'stavate', 'stavano', 'stetti', 'stesti', 'stette', 'stemmo', 'steste', 'stettero', 'stessi', 'stesse', 'stessimo', 'stessero', 'stando']\n"
     ]
    }
   ],
   "source": [
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46f3e2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../Korpus/Korpus/corpus_lemmatized.csv', sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d8fa580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>source</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>period</th>\n",
       "      <th>text_type</th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "      <th>lemmatized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Poesia.IV.11.Testo.txt</td>\n",
       "      <td>MIDIA</td>\n",
       "      <td>Giambattista Felice Zappi</td>\n",
       "      <td>Poesie</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1700-1750</td>\n",
       "      <td>poesia</td>\n",
       "      <td>IV. 11. Rime degli arcadi: Tirsi Leucasio (Gio...</td>\n",
       "      <td>6113.0</td>\n",
       "      <td>iv . 11 . rima del arcade : tirsi leucasio ( g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Personali.IV.5.Testo.txt</td>\n",
       "      <td>MIDIA</td>\n",
       "      <td>Lorenzo Magalotti</td>\n",
       "      <td>Lettere odorose (1693-1705)</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1700-1750</td>\n",
       "      <td>personale</td>\n",
       "      <td>IV. 5. Lorenzo Magalotti, Lettere odorose (169...</td>\n",
       "      <td>8374.0</td>\n",
       "      <td>iv . 5 . Lorenzo magalotti , lettere odoroso (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Espositivi.IV.4.Testo.txt</td>\n",
       "      <td>MIDIA</td>\n",
       "      <td>Ludovico Antonio Muratori</td>\n",
       "      <td>Antichità italiane</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1700-1750</td>\n",
       "      <td>espositivo</td>\n",
       "      <td>﻿IV. 4. Ludovico Antonio Muratori, Antichità i...</td>\n",
       "      <td>8990.0</td>\n",
       "      <td>﻿iv . 4 . Ludovico Antonio muratori , antichit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Personali.IV.15.Testo.txt</td>\n",
       "      <td>MIDIA</td>\n",
       "      <td>Pietro Giannone</td>\n",
       "      <td>Vita scritta da lui medesimo</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1700-1750</td>\n",
       "      <td>personale</td>\n",
       "      <td>[Proemio]\\nPrendo a scrivere la mia vita e qua...</td>\n",
       "      <td>10118.0</td>\n",
       "      <td>[ proemio ] \\n prendere a scrivere il mio vita...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Personali.IV.4.Testo.txt</td>\n",
       "      <td>MIDIA</td>\n",
       "      <td>Vincenzo da Filicaia</td>\n",
       "      <td>Lettere inedite a Lorenzo Magalotti</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1700-1750</td>\n",
       "      <td>personale</td>\n",
       "      <td>IV. 4. Vincenzo da Filicaia, Lettere inedite a...</td>\n",
       "      <td>10073.0</td>\n",
       "      <td>iv . 4 . Vincenzo da filicaia , lettere inedit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         doc source                      author  \\\n",
       "0     Poesia.IV.11.Testo.txt  MIDIA   Giambattista Felice Zappi   \n",
       "1   Personali.IV.5.Testo.txt  MIDIA           Lorenzo Magalotti   \n",
       "2  Espositivi.IV.4.Testo.txt  MIDIA  Ludovico Antonio Muratori    \n",
       "3  Personali.IV.15.Testo.txt  MIDIA             Pietro Giannone   \n",
       "4   Personali.IV.4.Testo.txt  MIDIA        Vincenzo da Filicaia   \n",
       "\n",
       "                                 title    year     period   text_type  \\\n",
       "0                               Poesie  1700.0  1700-1750      poesia   \n",
       "1          Lettere odorose (1693-1705)  1700.0  1700-1750   personale   \n",
       "2                   Antichità italiane  1700.0  1700-1750  espositivo   \n",
       "3         Vita scritta da lui medesimo  1700.0  1700-1750   personale   \n",
       "4  Lettere inedite a Lorenzo Magalotti  1700.0  1700-1750   personale   \n",
       "\n",
       "                                                text    words  \\\n",
       "0  IV. 11. Rime degli arcadi: Tirsi Leucasio (Gio...   6113.0   \n",
       "1  IV. 5. Lorenzo Magalotti, Lettere odorose (169...   8374.0   \n",
       "2  ﻿IV. 4. Ludovico Antonio Muratori, Antichità i...   8990.0   \n",
       "3  [Proemio]\\nPrendo a scrivere la mia vita e qua...  10118.0   \n",
       "4  IV. 4. Vincenzo da Filicaia, Lettere inedite a...  10073.0   \n",
       "\n",
       "                                     lemmatized_text  \n",
       "0  iv . 11 . rima del arcade : tirsi leucasio ( g...  \n",
       "1  iv . 5 . Lorenzo magalotti , lettere odoroso (...  \n",
       "2  ﻿iv . 4 . Ludovico Antonio muratori , antichit...  \n",
       "3  [ proemio ] \\n prendere a scrivere il mio vita...  \n",
       "4  iv . 4 . Vincenzo da filicaia , lettere inedit...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d8d584b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(304129, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f02b06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.text = df.text.fillna('')\n",
    "df.lemmatized_text = df.lemmatized_text.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fea6e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einzeldataframes für die Zeiträume\n",
    "\n",
    "df_periods = dict(tuple(df.groupby(by='period')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea8a1150",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_periods['1700-1750']\n",
    "df2 = df_periods['1751-1800']\n",
    "df3 = df_periods['1801-1825']\n",
    "df4 = df_periods['1826-1850']\n",
    "df5 = df_periods['1851-1875']\n",
    "df6 = df_periods['1876-1900']\n",
    "df7 = df_periods['1901-1925']\n",
    "df8 = df_periods['1926-1950']\n",
    "df9 = df_periods['1951-1985']\n",
    "df10 = df_periods['1986-2000']\n",
    "df11 = df_periods['2001-2021']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "524c665b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>source</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>period</th>\n",
       "      <th>text_type</th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "      <th>lemmatized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74265</th>\n",
       "      <td>diacorisBiagi1.txt</td>\n",
       "      <td>DiaCoris</td>\n",
       "      <td>Enzo Biagi</td>\n",
       "      <td>L'alluvione del Polesine</td>\n",
       "      <td>1951.0</td>\n",
       "      <td>1951-1985</td>\n",
       "      <td>stampa</td>\n",
       "      <td>L ' angoscia di un padre Si parla di battaglie...</td>\n",
       "      <td>152.0</td>\n",
       "      <td>l ' angoscia di uno padre si parlare di battag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74266</th>\n",
       "      <td>LISCastiglia1.txt</td>\n",
       "      <td>LIS</td>\n",
       "      <td>Roderigo di Castiglia</td>\n",
       "      <td>«Vittorini se n'è ghiuto/ E soli ci ha lasciat...</td>\n",
       "      <td>1951.0</td>\n",
       "      <td>1951-1985</td>\n",
       "      <td>stampa</td>\n",
       "      <td>A dire il vero , nelle nostre file pochi se ne...</td>\n",
       "      <td>1695.0</td>\n",
       "      <td>a dire il vero , nella nostro file pochi se ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74267</th>\n",
       "      <td>LISBianchi1.txt</td>\n",
       "      <td>LIS</td>\n",
       "      <td>Ranuccio Bianchi Bandinelli</td>\n",
       "      <td>Il nostro lavoro nella scuola</td>\n",
       "      <td>1951.0</td>\n",
       "      <td>1951-1985</td>\n",
       "      <td>stampa</td>\n",
       "      <td>Come in tutti i congressi , anche nel VII Cong...</td>\n",
       "      <td>2898.0</td>\n",
       "      <td>come in tutto il congresso , anche nel vii con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74268</th>\n",
       "      <td>LLAlbertelli1.txt</td>\n",
       "      <td>Liber Liber</td>\n",
       "      <td>Pilo Albertelli</td>\n",
       "      <td>Rousseau</td>\n",
       "      <td>1951.0</td>\n",
       "      <td>1951-1985</td>\n",
       "      <td>prosa letteraria</td>\n",
       "      <td>﻿Pilo Albertelli\\nRousseau\\n\\n  Nacque il 28 g...</td>\n",
       "      <td>4894.0</td>\n",
       "      <td>﻿pilo albertelli \\n rousseau \\n\\n   nascere il...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74269</th>\n",
       "      <td>LISJotti1.txt</td>\n",
       "      <td>LIS</td>\n",
       "      <td>Nilde Jotti</td>\n",
       "      <td>La questione dei fumetti</td>\n",
       "      <td>1951.0</td>\n",
       "      <td>1951-1985</td>\n",
       "      <td>stampa</td>\n",
       "      <td>Il dibattito sulla stampa a fumetti per i raga...</td>\n",
       "      <td>2785.0</td>\n",
       "      <td>il dibattito sulla stampa a fumetto per il rag...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      doc       source                       author  \\\n",
       "74265  diacorisBiagi1.txt     DiaCoris                   Enzo Biagi   \n",
       "74266   LISCastiglia1.txt          LIS        Roderigo di Castiglia   \n",
       "74267     LISBianchi1.txt          LIS  Ranuccio Bianchi Bandinelli   \n",
       "74268   LLAlbertelli1.txt  Liber Liber              Pilo Albertelli   \n",
       "74269       LISJotti1.txt          LIS                  Nilde Jotti   \n",
       "\n",
       "                                                   title    year     period  \\\n",
       "74265                           L'alluvione del Polesine  1951.0  1951-1985   \n",
       "74266  «Vittorini se n'è ghiuto/ E soli ci ha lasciat...  1951.0  1951-1985   \n",
       "74267                     Il nostro lavoro nella scuola   1951.0  1951-1985   \n",
       "74268                                           Rousseau  1951.0  1951-1985   \n",
       "74269                           La questione dei fumetti  1951.0  1951-1985   \n",
       "\n",
       "              text_type                                               text  \\\n",
       "74265            stampa  L ' angoscia di un padre Si parla di battaglie...   \n",
       "74266            stampa  A dire il vero , nelle nostre file pochi se ne...   \n",
       "74267            stampa  Come in tutti i congressi , anche nel VII Cong...   \n",
       "74268  prosa letteraria  ﻿Pilo Albertelli\\nRousseau\\n\\n  Nacque il 28 g...   \n",
       "74269            stampa  Il dibattito sulla stampa a fumetti per i raga...   \n",
       "\n",
       "        words                                    lemmatized_text  \n",
       "74265   152.0  l ' angoscia di uno padre si parlare di battag...  \n",
       "74266  1695.0  a dire il vero , nella nostro file pochi se ne...  \n",
       "74267  2898.0  come in tutto il congresso , anche nel vii con...  \n",
       "74268  4894.0  ﻿pilo albertelli \\n rousseau \\n\\n   nascere il...  \n",
       "74269  2785.0  il dibattito sulla stampa a fumetto per il rag...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df9.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8298b52a",
   "metadata": {},
   "source": [
    "## Training von Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44b8d2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hilfsfunktionen zur Vorbereitung auf das Training\n",
    "# Bereinigung und Tokenisierung\n",
    "\n",
    "def sentence_to_wordlist(raw:str):\n",
    "    \"\"\"\n",
    "    cleans and tokenizes the sentences\n",
    "    \"\"\"\n",
    "    text = re.sub('[^A-Za-z_àÀèÈìÌòÒùÙáÁéÉíÍóÓúÚ]',' ', raw).split()        # Diakritika ans Italienische anpassen                    \n",
    "    filtered_text = [word for word in text if word not in stopwords]        # Stopwörter löschen\n",
    "    return filtered_text\n",
    "\n",
    "\n",
    "def tokenize_text(raw_text):\n",
    "    \"\"\"\n",
    "    returns a list of lowercase tokenized sentences \n",
    "    \"\"\"\n",
    "    raw_sentences = tokenizer.tokenize(str(raw_text).lower())    \n",
    "    tokenized_sentences = Parallel(n_jobs=-1)(delayed(sentence_to_wordlist)(raw_sentence) for raw_sentence in raw_sentences)\n",
    "    sentences = tokenized_sentences\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "167dbe44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainingsparamter setzen\n",
    "\n",
    "vector_size = 300                  # Dimensionality of the word vectors\n",
    "window = 5                         # The maximum distance between the current and predicted word within a sentence\n",
    "min_count = 1                      # (int, optional) – The model ignores all words with total frequency lower than this\n",
    "workers = 1                        # Use these many worker threads to train the model (faster training with multicore machines)\n",
    "min_alpha = 0.0001                 # Learning rate will linearly drop to min_alpha as training progresses\n",
    "sg = 1                             # Training algorithm: skip-gram if sg=1, otherwise CBOW            \n",
    "seed = 1                           # Reproductivity --> only if workers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cab9952f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordner anlegen zum Abspeichern von trainierten Modellen\n",
    "\n",
    "if not os.path.exists('../trained_models'):\n",
    "    os.makedirs('../trained_models')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8d041b",
   "metadata": {},
   "source": [
    "### Zeitraum 1: 1700-1750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a28475c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatisierte Texte zu einem String verbinden\n",
    "\n",
    "text1 = ''\n",
    "\n",
    "for i in df1.lemmatized_text:\n",
    "    text1 += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd305b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 17.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences1 = tokenize_text(text1)         # Bereinigen, Tokenisieren und in Form bringen (Ziel: Liste von tokenisierten Sätzen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d40ec629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lungo', 'inospita', 'campagna', 'aggiungere', 'invidia', 'lato', 'manco', 'dire', 'anch', 'essere', 'teco', 'labbro', 'bianco', 'veggo', 'veneno', 'cor', 'stagno']\n"
     ]
    }
   ],
   "source": [
    "print(sentences1[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0547e952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113328"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f3bbf96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Training   \n",
    "\n",
    "w2v1 = Word2Vec(sentences=sentences1,                      \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac18caca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sconfiggere', 0.7859934568405151),\n",
       " ('desolazione', 0.780498743057251),\n",
       " ('sacco', 0.7795285582542419),\n",
       " ('rumore', 0.7793293595314026),\n",
       " ('costernazione', 0.7699690461158752),\n",
       " ('riempiè', 0.7684776186943054),\n",
       " ('spavento', 0.7665495276451111),\n",
       " ('peste', 0.7642766237258911),\n",
       " ('macello', 0.763086199760437),\n",
       " ('torma', 0.7604858875274658)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v1.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ddba9921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainiertes Modell speichern\n",
    "\n",
    "w2v1.save(os.path.join('../trained_models/Word2Vec20', '20w2v1.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd3a0bc",
   "metadata": {},
   "source": [
    "### Zeitraum 2: 1751-1800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f4c26d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = ''\n",
    "\n",
    "for i in df2.lemmatized_text:\n",
    "    text2 += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eaa2b3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 20.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences2 = tokenize_text(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ee58cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v2 = Word2Vec(sentences=sentences2,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f2382df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('letargo', 0.8964829444885254),\n",
       " ('varco', 0.8940438628196716),\n",
       " ('respingere', 0.8908490538597107),\n",
       " ('scherno', 0.889966607093811),\n",
       " ('colmo', 0.8884931802749634),\n",
       " ('fantasma', 0.887101948261261),\n",
       " ('ruina', 0.8856281638145447),\n",
       " ('usurpatore', 0.8839372992515564),\n",
       " ('sprone', 0.883405864238739),\n",
       " ('retaggio', 0.8831426501274109)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v2.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "912ce604",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v2.save(os.path.join('../trained_models/Word2Vec20', '20w2v2.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12799bcb",
   "metadata": {},
   "source": [
    "### Zeitraum 3: 1801-1825"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31895854",
   "metadata": {},
   "outputs": [],
   "source": [
    "text3 = ''\n",
    "\n",
    "for i in df3.lemmatized_text:\n",
    "    text3 += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b20f1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences3 = tokenize_text(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f33cd50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v3 = Word2Vec(sentences=sentences3,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc887350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('turpe', 0.8612518310546875),\n",
       " ('avversa', 0.8523948192596436),\n",
       " ('infiammare', 0.8513959646224976),\n",
       " ('rinfrancare', 0.8452512621879578),\n",
       " ('rissa', 0.8443565368652344),\n",
       " ('orrore', 0.8438355922698975),\n",
       " ('vituperio', 0.8437812328338623),\n",
       " ('avvampare', 0.8431482911109924),\n",
       " ('furore', 0.8428069353103638),\n",
       " ('impotente', 0.8406247496604919)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v3.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6a8e8201",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v3.save(os.path.join('../trained_models/Word2Vec20', '20w2v3.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7ad1fa",
   "metadata": {},
   "source": [
    "### Zeitraum 4: 1826-1850"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dfc8abc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text4 = ''\n",
    "\n",
    "for i in df4.lemmatized_text:\n",
    "    text4 += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4d304d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences4 = tokenize_text(text4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0186858c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v4 = Word2Vec(sentences=sentences4,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6985b1e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('furore', 0.8491377234458923),\n",
       " ('opprimere', 0.8358274698257446),\n",
       " ('indegnazione', 0.8315457701683044),\n",
       " ('smisurato', 0.8273174166679382),\n",
       " ('sfrenato', 0.8239211440086365),\n",
       " ('furor', 0.8234388828277588),\n",
       " ('gelosia', 0.8214377760887146),\n",
       " ('frenare', 0.8137011528015137),\n",
       " ('sdegno', 0.813094973564148),\n",
       " ('servaggio', 0.810877799987793)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v4.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "33c0263d",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v4.save(os.path.join('../trained_models/Word2Vec20', '20w2v4.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adbc52f",
   "metadata": {},
   "source": [
    "### Zeitraum 5: 1851-1875"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "14f4f694",
   "metadata": {},
   "outputs": [],
   "source": [
    "text5 = ''\n",
    "\n",
    "for i in df5.lemmatized_text:\n",
    "    text5 += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4a37ae9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences5 = tokenize_text(text5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "14e061e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v5 = Word2Vec(sentences=sentences5,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5dcf457a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sgomento', 0.8857079744338989),\n",
       " ('disperazione', 0.8782998323440552),\n",
       " ('fremito', 0.8756722211837769),\n",
       " ('assalire', 0.8710376620292664),\n",
       " ('esaltazione', 0.8659152388572693),\n",
       " ('sdegno', 0.8635143637657166),\n",
       " ('impeto', 0.8620864152908325),\n",
       " ('furore', 0.8614261746406555),\n",
       " ('atterrire', 0.8593610525131226),\n",
       " ('spavento', 0.8576532006263733)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v5.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "890b9950",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v5.save(os.path.join('../trained_models/Word2Vec20', '20w2v5.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8264d8",
   "metadata": {},
   "source": [
    "### Zeitraum 6: 1876-1900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3602dbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text6 = ''\n",
    "\n",
    "for i in df6.lemmatized_text:\n",
    "    text6 += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e68bdf54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 17.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences6 = tokenize_text(text6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "396efd17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v6 = Word2Vec(sentences=sentences6,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ee88f9b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tremendo', 0.8208913803100586),\n",
       " ('sgomento', 0.8197522163391113),\n",
       " ('furore', 0.8174567222595215),\n",
       " ('spavento', 0.8136556148529053),\n",
       " ('parossismo', 0.806135892868042),\n",
       " ('orrore', 0.805837094783783),\n",
       " ('crisi', 0.8024734854698181),\n",
       " ('accesso', 0.8006179928779602),\n",
       " ('convulsione', 0.7991422414779663),\n",
       " ('violento', 0.797741711139679)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v6.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2a67be2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v6.save(os.path.join('../trained_models/Word2Vec20', '20w2v6.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd33346",
   "metadata": {},
   "source": [
    "### Zeitraum 7: 1901-1925"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6c7fc2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text7 = ''\n",
    "\n",
    "for i in df7.lemmatized_text:\n",
    "    text7 += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a61dff94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 17.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences7 = tokenize_text(text7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "274ece89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v7 = Word2Vec(sentences=sentences7,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f97859ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('indicibile', 0.8450005054473877),\n",
       " ('furore', 0.8355855941772461),\n",
       " ('indignazione', 0.8322768211364746),\n",
       " ('spavento', 0.8295801281929016),\n",
       " ('commozione', 0.8287470936775208),\n",
       " ('subitaneo', 0.8280487656593323),\n",
       " ('orrore', 0.8279702663421631),\n",
       " ('smarrimento', 0.8247280716896057),\n",
       " ('straziante', 0.8195492029190063),\n",
       " ('invocazione', 0.813363790512085)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v7.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f3cec0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v7.save(os.path.join('../trained_models/Word2Vec20', '20w2v7.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54934b98",
   "metadata": {},
   "source": [
    "### Zeitraum 8: 1926-1950"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9f32ad8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text8 = ''\n",
    "\n",
    "for i in df8.lemmatized_text:\n",
    "    text8 += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "56c2283a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences8 = tokenize_text(text8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "20ed4b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v8 = Word2Vec(sentences=sentences8,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7a676dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spavento', 0.871465265750885),\n",
       " ('orrore', 0.85284423828125),\n",
       " ('raccapriccio', 0.8386695384979248),\n",
       " ('sussulto', 0.8377180695533752),\n",
       " ('ribrezzo', 0.8360605239868164),\n",
       " ('subitaneo', 0.8339870572090149),\n",
       " ('repentino', 0.8238382339477539),\n",
       " ('disgusto', 0.8218224048614502),\n",
       " ('disperazione', 0.8204032778739929),\n",
       " ('impeto', 0.8185206055641174)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v8.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c618a253",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v8.save(os.path.join('../trained_models/Word2Vec20', '20w2v8.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffecf4f1",
   "metadata": {},
   "source": [
    "### Zeitraum 9: 1951-1985"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "afe767d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text9 = ''\n",
    "\n",
    "for i in df9.lemmatized_text:\n",
    "    text9 += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0e4c1914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 18.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences9 = tokenize_text(text9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e840054a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v9 = Word2Vec(sentences=sentences9,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dad6d0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sconvolgere', 0.7701098918914795),\n",
       " ('orrore', 0.7662425637245178),\n",
       " ('sanguinoso', 0.7416909337043762),\n",
       " ('immane', 0.7406674027442932),\n",
       " ('seminare', 0.7350096106529236),\n",
       " ('annientare', 0.7332013249397278),\n",
       " ('panico', 0.7278039455413818),\n",
       " ('valanga', 0.7269976139068604),\n",
       " ('orribile', 0.7264589071273804),\n",
       " ('smarrimento', 0.7228153944015503)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v9.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1f840943",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v9.save(os.path.join('../trained_models/Word2Vec20', '20w2v9.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7eb5cd",
   "metadata": {},
   "source": [
    "### Zeitraum 10: 1986-2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b8d34fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text10 = ''\n",
    "\n",
    "for i in df10.lemmatized_text:\n",
    "    text10+= i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ed3d4cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 36.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences10 = tokenize_text(text10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "35c08bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v10 = Word2Vec(sentences=sentences10,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "60227ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('seminare', 0.8658721446990967),\n",
       " ('cieco', 0.8464635014533997),\n",
       " ('sanguinoso', 0.8413199782371521),\n",
       " ('insanguinare', 0.8394982814788818),\n",
       " ('spaventoso', 0.8345075845718384),\n",
       " ('lutto', 0.8317131400108337),\n",
       " ('rabbia', 0.825316846370697),\n",
       " ('ferita', 0.823995053768158),\n",
       " ('tremendo', 0.8232277631759644),\n",
       " ('disperazione', 0.8220595717430115)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v10.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e3c2b7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v10.save(os.path.join('../trained_models/Word2Vec20', '20w2v10.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54297223",
   "metadata": {},
   "source": [
    "### Zeitraum 11: 2001-2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2238429e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text11 = ''\n",
    "\n",
    "for i in df11.lemmatized_text:\n",
    "    text11+= i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c480ef84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences11 = tokenize_text(text11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b2b457e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v11 = Word2Vec(sentences=sentences11,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f0a144e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('seminare', 0.9111881256103516),\n",
       " ('disperazione', 0.8982512950897217),\n",
       " ('barbaro', 0.8962597846984863),\n",
       " ('distruzione', 0.8941064476966858),\n",
       " ('sgomento', 0.8940295577049255),\n",
       " ('tormento', 0.8920628428459167),\n",
       " ('soffocare', 0.8893533945083618),\n",
       " ('dèi', 0.888884425163269),\n",
       " ('atrocemente', 0.8887830972671509),\n",
       " ('angoscia', 0.8886421322822571)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v11.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4e6a41fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v11.save(os.path.join('../trained_models/Word2Vec20', '20w2v11.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02105e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
