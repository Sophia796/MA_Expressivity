{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ba672df",
   "metadata": {},
   "source": [
    "# Trainingspipeline 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bb0ffc",
   "metadata": {},
   "source": [
    "- ohne Bigramme\n",
    "- vector_size: 300\n",
    "- window: 10\n",
    "- seed: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08e5260c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import nltk\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import scipy\n",
    "import spacy\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from joblib import Parallel, delayed  \n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09922b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stopwords.words('italian')\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/italian.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46f3e2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Korpus/Korpus/corpus_final.csv', sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d8fa580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>source</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>period</th>\n",
       "      <th>text_type</th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "      <th>lemmatized_text</th>\n",
       "      <th>cleaned_tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Poesia.IV.4.Testo.txt</td>\n",
       "      <td>MIDIA</td>\n",
       "      <td>Faustina Maratti Zappi</td>\n",
       "      <td>Poesie</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1700-1750</td>\n",
       "      <td>poesia</td>\n",
       "      <td>IV. 4. Rime degli Arcadi: Aglauro Cidonia (Fau...</td>\n",
       "      <td>3184.0</td>\n",
       "      <td>iv . 4 . rima del arcadi : aglauro cidonia ( f...</td>\n",
       "      <td>[['iv'], [], ['rima', 'arcadi', 'aglauro', 'ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Espositivi.IV.4.Testo.txt</td>\n",
       "      <td>MIDIA</td>\n",
       "      <td>Ludovico Antonio Muratori</td>\n",
       "      <td>Antichità italiane</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1700-1750</td>\n",
       "      <td>espositivo</td>\n",
       "      <td>﻿IV. 4. Ludovico Antonio Muratori, Antichità i...</td>\n",
       "      <td>8990.0</td>\n",
       "      <td>﻿iv . 4 . Ludovico Antonio muratori , antichit...</td>\n",
       "      <td>[['iv'], [], ['ludovico', 'antonio', 'muratori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Personali.IV.5.Testo.txt</td>\n",
       "      <td>MIDIA</td>\n",
       "      <td>Lorenzo Magalotti</td>\n",
       "      <td>Lettere odorose (1693-1705)</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1700-1750</td>\n",
       "      <td>personale</td>\n",
       "      <td>IV. 5. Lorenzo Magalotti, Lettere odorose (169...</td>\n",
       "      <td>8374.0</td>\n",
       "      <td>iv . 5 . Lorenzo magalotti , lettere odoroso (...</td>\n",
       "      <td>[['iv'], [], ['lorenzo', 'magalotti', 'lettere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Personali.IV.15.Testo.txt</td>\n",
       "      <td>MIDIA</td>\n",
       "      <td>Pietro Giannone</td>\n",
       "      <td>Vita scritta da lui medesimo</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1700-1750</td>\n",
       "      <td>personale</td>\n",
       "      <td>[Proemio]\\nPrendo a scrivere la mia vita e qua...</td>\n",
       "      <td>10118.0</td>\n",
       "      <td>[ proemio ] \\n prendere a scrivere il mio vita...</td>\n",
       "      <td>[['proemio', 'prendere', 'scrivere', 'vita', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Personali.IV.4.Testo.txt</td>\n",
       "      <td>MIDIA</td>\n",
       "      <td>Vincenzo da Filicaia</td>\n",
       "      <td>Lettere inedite a Lorenzo Magalotti</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1700-1750</td>\n",
       "      <td>personale</td>\n",
       "      <td>IV. 4. Vincenzo da Filicaia, Lettere inedite a...</td>\n",
       "      <td>10073.0</td>\n",
       "      <td>iv . 4 . Vincenzo da filicaia , lettere inedit...</td>\n",
       "      <td>[['iv'], [], ['vincenzo', 'filicaia', 'lettere...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         doc source                      author  \\\n",
       "0      Poesia.IV.4.Testo.txt  MIDIA      Faustina Maratti Zappi   \n",
       "1  Espositivi.IV.4.Testo.txt  MIDIA  Ludovico Antonio Muratori    \n",
       "2   Personali.IV.5.Testo.txt  MIDIA           Lorenzo Magalotti   \n",
       "3  Personali.IV.15.Testo.txt  MIDIA             Pietro Giannone   \n",
       "4   Personali.IV.4.Testo.txt  MIDIA        Vincenzo da Filicaia   \n",
       "\n",
       "                                 title    year     period   text_type  \\\n",
       "0                               Poesie  1700.0  1700-1750      poesia   \n",
       "1                   Antichità italiane  1700.0  1700-1750  espositivo   \n",
       "2          Lettere odorose (1693-1705)  1700.0  1700-1750   personale   \n",
       "3         Vita scritta da lui medesimo  1700.0  1700-1750   personale   \n",
       "4  Lettere inedite a Lorenzo Magalotti  1700.0  1700-1750   personale   \n",
       "\n",
       "                                                text    words  \\\n",
       "0  IV. 4. Rime degli Arcadi: Aglauro Cidonia (Fau...   3184.0   \n",
       "1  ﻿IV. 4. Ludovico Antonio Muratori, Antichità i...   8990.0   \n",
       "2  IV. 5. Lorenzo Magalotti, Lettere odorose (169...   8374.0   \n",
       "3  [Proemio]\\nPrendo a scrivere la mia vita e qua...  10118.0   \n",
       "4  IV. 4. Vincenzo da Filicaia, Lettere inedite a...  10073.0   \n",
       "\n",
       "                                     lemmatized_text  \\\n",
       "0  iv . 4 . rima del arcadi : aglauro cidonia ( f...   \n",
       "1  ﻿iv . 4 . Ludovico Antonio muratori , antichit...   \n",
       "2  iv . 5 . Lorenzo magalotti , lettere odoroso (...   \n",
       "3  [ proemio ] \\n prendere a scrivere il mio vita...   \n",
       "4  iv . 4 . Vincenzo da filicaia , lettere inedit...   \n",
       "\n",
       "                              cleaned_tokenized_text  \n",
       "0  [['iv'], [], ['rima', 'arcadi', 'aglauro', 'ci...  \n",
       "1  [['iv'], [], ['ludovico', 'antonio', 'muratori...  \n",
       "2  [['iv'], [], ['lorenzo', 'magalotti', 'lettere...  \n",
       "3  [['proemio', 'prendere', 'scrivere', 'vita', '...  \n",
       "4  [['iv'], [], ['vincenzo', 'filicaia', 'lettere...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d8d584b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(710840, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f02b06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.text = df.text.fillna('')\n",
    "df.lemmatized_text = df.lemmatized_text.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fea6e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einzeldataframes für die Zeiträume\n",
    "\n",
    "df_periods = dict(tuple(df.groupby(by='period')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea8a1150",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_periods['1700-1750']\n",
    "df2 = df_periods['1751-1800']\n",
    "df3 = df_periods['1801-1825']\n",
    "df4 = df_periods['1826-1850']\n",
    "df5 = df_periods['1851-1875']\n",
    "df6 = df_periods['1876-1900']\n",
    "df7 = df_periods['1901-1925']\n",
    "df8 = df_periods['1926-1950']\n",
    "df9 = df_periods['1951-1975']\n",
    "df10 = df_periods['1976-2000']\n",
    "df11 = df_periods['2001-2010']\n",
    "df12 = df_periods['2011-2016']\n",
    "df13 = df_periods['2017-2021']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "524c665b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>source</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>period</th>\n",
       "      <th>text_type</th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "      <th>lemmatized_text</th>\n",
       "      <th>cleaned_tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94810</th>\n",
       "      <td>LISRodari3.txt</td>\n",
       "      <td>LIS</td>\n",
       "      <td>Gianno Rodari</td>\n",
       "      <td>La questione dei fumetti</td>\n",
       "      <td>1951.0</td>\n",
       "      <td>1951-1975</td>\n",
       "      <td>stampa</td>\n",
       "      <td>Caro Direttore , ho letto nell ' ultimo numero...</td>\n",
       "      <td>1510.0</td>\n",
       "      <td>caro direttore , avere leggere nell ' ultimo n...</td>\n",
       "      <td>[['caro', 'direttore', 'avere', 'leggere', 'ul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94811</th>\n",
       "      <td>LISJotti1.txt</td>\n",
       "      <td>LIS</td>\n",
       "      <td>Nilde Jotti</td>\n",
       "      <td>La questione dei fumetti</td>\n",
       "      <td>1951.0</td>\n",
       "      <td>1951-1975</td>\n",
       "      <td>stampa</td>\n",
       "      <td>Il dibattito sulla stampa a fumetti per i raga...</td>\n",
       "      <td>2785.0</td>\n",
       "      <td>il dibattito sulla stampa a fumetto per il rag...</td>\n",
       "      <td>[['dibattito', 'stampa', 'fumetto', 'ragazzo',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94812</th>\n",
       "      <td>LLAlbertelli1.txt</td>\n",
       "      <td>Liber Liber</td>\n",
       "      <td>Pilo Albertelli</td>\n",
       "      <td>Rousseau</td>\n",
       "      <td>1951.0</td>\n",
       "      <td>1951-1975</td>\n",
       "      <td>prosa letteraria</td>\n",
       "      <td>﻿Pilo Albertelli\\nRousseau\\n\\n  Nacque il 28 g...</td>\n",
       "      <td>4894.0</td>\n",
       "      <td>﻿pilo albertelli \\n rousseau \\n\\n   nascere il...</td>\n",
       "      <td>[['pilo', 'albertelli', 'rousseau', 'nascere',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94813</th>\n",
       "      <td>LISManacorda1.txt</td>\n",
       "      <td>LIS</td>\n",
       "      <td>Gastone Manacorda</td>\n",
       "      <td>Il Partito e la sua funzione di guida nel camp...</td>\n",
       "      <td>1951.0</td>\n",
       "      <td>1951-1975</td>\n",
       "      <td>stampa</td>\n",
       "      <td>Al partito , nel suo rigoglioso sviluppo , seg...</td>\n",
       "      <td>3460.0</td>\n",
       "      <td>al partito , nel suo rigoglioso sviluppo , seg...</td>\n",
       "      <td>[['partito', 'rigoglioso', 'sviluppo', 'seguit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94814</th>\n",
       "      <td>LISBianchi1.txt</td>\n",
       "      <td>LIS</td>\n",
       "      <td>Ranuccio Bianchi Bandinelli</td>\n",
       "      <td>Il nostro lavoro nella scuola</td>\n",
       "      <td>1951.0</td>\n",
       "      <td>1951-1975</td>\n",
       "      <td>stampa</td>\n",
       "      <td>Come in tutti i congressi , anche nel VII Cong...</td>\n",
       "      <td>2898.0</td>\n",
       "      <td>come in tutto il congresso , anche nel vii con...</td>\n",
       "      <td>[['congresso', 'vii', 'congresso', 'p'], ['tes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     doc       source                       author  \\\n",
       "94810     LISRodari3.txt          LIS                Gianno Rodari   \n",
       "94811      LISJotti1.txt          LIS                  Nilde Jotti   \n",
       "94812  LLAlbertelli1.txt  Liber Liber              Pilo Albertelli   \n",
       "94813  LISManacorda1.txt          LIS            Gastone Manacorda   \n",
       "94814    LISBianchi1.txt          LIS  Ranuccio Bianchi Bandinelli   \n",
       "\n",
       "                                                   title    year     period  \\\n",
       "94810                           La questione dei fumetti  1951.0  1951-1975   \n",
       "94811                           La questione dei fumetti  1951.0  1951-1975   \n",
       "94812                                           Rousseau  1951.0  1951-1975   \n",
       "94813  Il Partito e la sua funzione di guida nel camp...  1951.0  1951-1975   \n",
       "94814                     Il nostro lavoro nella scuola   1951.0  1951-1975   \n",
       "\n",
       "              text_type                                               text  \\\n",
       "94810            stampa  Caro Direttore , ho letto nell ' ultimo numero...   \n",
       "94811            stampa  Il dibattito sulla stampa a fumetti per i raga...   \n",
       "94812  prosa letteraria  ﻿Pilo Albertelli\\nRousseau\\n\\n  Nacque il 28 g...   \n",
       "94813            stampa  Al partito , nel suo rigoglioso sviluppo , seg...   \n",
       "94814            stampa  Come in tutti i congressi , anche nel VII Cong...   \n",
       "\n",
       "        words                                    lemmatized_text  \\\n",
       "94810  1510.0  caro direttore , avere leggere nell ' ultimo n...   \n",
       "94811  2785.0  il dibattito sulla stampa a fumetto per il rag...   \n",
       "94812  4894.0  ﻿pilo albertelli \\n rousseau \\n\\n   nascere il...   \n",
       "94813  3460.0  al partito , nel suo rigoglioso sviluppo , seg...   \n",
       "94814  2898.0  come in tutto il congresso , anche nel vii con...   \n",
       "\n",
       "                                  cleaned_tokenized_text  \n",
       "94810  [['caro', 'direttore', 'avere', 'leggere', 'ul...  \n",
       "94811  [['dibattito', 'stampa', 'fumetto', 'ragazzo',...  \n",
       "94812  [['pilo', 'albertelli', 'rousseau', 'nascere',...  \n",
       "94813  [['partito', 'rigoglioso', 'sviluppo', 'seguit...  \n",
       "94814  [['congresso', 'vii', 'congresso', 'p'], ['tes...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df9.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8298b52a",
   "metadata": {},
   "source": [
    "## Training von Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44b8d2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hilfsfunktionen zur Vorbereitung auf das Training\n",
    "# Bereinigung und Tokenisierung\n",
    "\n",
    "def sentence_to_wordlist(raw:str):\n",
    "    \"\"\"\n",
    "    cleans and tokenizes the sentences\n",
    "    \"\"\"\n",
    "    text = re.sub('[^A-Za-z_àÀèÈìÌòÒùÙáÁéÉíÍóÓúÚ]',' ', raw).split()        # Diakritika ans Italienische anpassen                    \n",
    "    filtered_text = [word for word in text if word not in stopwords]        # Stopwörter löschen\n",
    "    return filtered_text\n",
    "\n",
    "\n",
    "def tokenize_text(raw_text):\n",
    "    \"\"\"\n",
    "    returns a list of lowercase tokenized sentences \n",
    "    \"\"\"\n",
    "    raw_sentences = tokenizer.tokenize(str(raw_text).lower())    \n",
    "    tokenized_sentences = Parallel(n_jobs=-1)(delayed(sentence_to_wordlist)(raw_sentence) for raw_sentence in raw_sentences)\n",
    "    sentences = tokenized_sentences\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "167dbe44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainingsparamter setzen\n",
    "\n",
    "vector_size = 300                  # Dimensionality of the word vectors\n",
    "window = 10                        # The maximum distance between the current and predicted word within a sentence\n",
    "min_count = 2                      # (int, optional) – The model ignores all words with total frequency lower than this\n",
    "workers = 1                        # Use these many worker threads to train the model (faster training with multicore machines)\n",
    "min_alpha = 0.0001                 # Learning rate will linearly drop to min_alpha as training progresses\n",
    "sg = 1                             # Training algorithm: skip-gram if sg=1, otherwise CBOW            \n",
    "seed = 1                           # Reproductivity --> only if workers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cab9952f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordner anlegen zum Abspeichern von trainierten Modellen\n",
    "\n",
    "if not os.path.exists('../trained_models'):\n",
    "    os.makedirs('../trained_models')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8d041b",
   "metadata": {},
   "source": [
    "### Zeitraum 1: 1700-1750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a28475c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatisierte Texte zu einem String verbinden\n",
    "\n",
    "text1 = ''\n",
    "\n",
    "for i in df1.lemmatized_text:\n",
    "    text1 += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd305b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences1 = tokenize_text(text1)         # Bereinigen, Tokenisieren und in Form bringen (Ziel: Liste von tokenisierten Sätzen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f3bbf96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Training   \n",
    "\n",
    "w2v1 = Word2Vec(sentences=sentences1,                      \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac18caca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spavento', 0.7756545543670654),\n",
       " ('goti', 0.7169016599655151),\n",
       " ('armi', 0.6985787749290466),\n",
       " ('barbari', 0.6858229041099548),\n",
       " ('spaventare', 0.6662147045135498),\n",
       " ('contrada', 0.6626530289649963),\n",
       " ('germani', 0.6611461043357849),\n",
       " ('addossare', 0.6580222249031067),\n",
       " ('imminente', 0.650904655456543),\n",
       " ('riempiè', 0.6502344608306885)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v1.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddba9921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainiertes Modell speichern\n",
    "\n",
    "w2v1.save(os.path.join('../trained_models/Word2Vec3', '3w2v1.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd3a0bc",
   "metadata": {},
   "source": [
    "### Zeitraum 2: 1751-1800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f4c26d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = ''\n",
    "\n",
    "for i in df2.lemmatized_text:\n",
    "    text2 += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eaa2b3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences2 = tokenize_text(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ee58cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v2 = Word2Vec(sentences=sentences2,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f2382df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spavento', 0.6814582943916321),\n",
       " ('ostile', 0.6737642884254456),\n",
       " ('barbari', 0.6570187211036682),\n",
       " ('inspirare', 0.6553183794021606),\n",
       " ('legione', 0.6471216082572937),\n",
       " ('strage', 0.6394809484481812),\n",
       " ('tribù', 0.6388413906097412),\n",
       " ('formidabile', 0.6361843347549438),\n",
       " ('franchi', 0.6307187676429749),\n",
       " ('atterrire', 0.6269368529319763)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v2.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "912ce604",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v2.save(os.path.join('../trained_models/Word2Vec3', '3w2v2.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12799bcb",
   "metadata": {},
   "source": [
    "### Zeitraum 3: 1801-1825"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "31895854",
   "metadata": {},
   "outputs": [],
   "source": [
    "text3 = ''\n",
    "\n",
    "for i in df3.lemmatized_text:\n",
    "    text3 += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b20f1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences3 = tokenize_text(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f33cd50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v3 = Word2Vec(sentences=sentences3,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc887350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('atterrire', 0.7579506635665894),\n",
       " ('repentino', 0.7577918171882629),\n",
       " ('spavento', 0.746575653553009),\n",
       " ('calma', 0.7460311651229858),\n",
       " ('eccitare', 0.7373303174972534),\n",
       " ('abbattimento', 0.728701114654541),\n",
       " ('soccombere', 0.7277485728263855),\n",
       " ('sollevare', 0.7234610319137573),\n",
       " ('sorpresa', 0.7222800850868225),\n",
       " ('impadronisce', 0.7209911942481995)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v3.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6a8e8201",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v3.save(os.path.join('../trained_models/Word2Vec3', '3w2v3.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7ad1fa",
   "metadata": {},
   "source": [
    "### Zeitraum 4: 1826-1850"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dfc8abc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text4 = ''\n",
    "\n",
    "for i in df4.lemmatized_text:\n",
    "    text4 += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d304d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences4 = tokenize_text(text4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0186858c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v4 = Word2Vec(sentences=sentences4,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6985b1e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spavento', 0.6172870397567749),\n",
       " ('cagionare', 0.5273274183273315),\n",
       " ('buonaparte', 0.5181800723075867),\n",
       " ('bentosto', 0.5089895129203796),\n",
       " ('inspirare', 0.5076649785041809),\n",
       " ('panico', 0.506298840045929),\n",
       " ('fuga', 0.49897563457489014),\n",
       " ('inaspettato', 0.4964360296726227),\n",
       " ('atterrire', 0.49357348680496216),\n",
       " ('colpire', 0.4899095892906189)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v4.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "33c0263d",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v4.save(os.path.join('../trained_models/Word2Vec3', '3w2v4.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adbc52f",
   "metadata": {},
   "source": [
    "### Zeitraum 5: 1851-1875"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "14f4f694",
   "metadata": {},
   "outputs": [],
   "source": [
    "text5 = ''\n",
    "\n",
    "for i in df5.lemmatized_text:\n",
    "    text5 += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a37ae9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 23.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences5 = tokenize_text(text5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "14e061e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v5 = Word2Vec(sentences=sentences5,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5dcf457a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sgomento', 0.5722348690032959),\n",
       " ('spavento', 0.54362952709198),\n",
       " ('orrore', 0.5253002643585205),\n",
       " ('rabbia', 0.5158381462097168),\n",
       " ('gioja', 0.5135176181793213),\n",
       " ('rammarichío', 0.5075597763061523),\n",
       " ('raccapriccio', 0.5061434507369995),\n",
       " ('tradito', 0.5018460750579834),\n",
       " ('agonia', 0.4989558458328247),\n",
       " ('atterriti', 0.4980342984199524)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v5.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "890b9950",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v5.save(os.path.join('../trained_models/Word2Vec3', '3w2v5.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8264d8",
   "metadata": {},
   "source": [
    "### Zeitraum 6: 1876-1900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3602dbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text6 = ''\n",
    "\n",
    "for i in df6.lemmatized_text:\n",
    "    text6 += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e68bdf54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 26.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences6 = tokenize_text(text6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "396efd17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v6 = Word2Vec(sentences=sentences6,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ee88f9b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spavento', 0.49233606457710266),\n",
       " ('sgomento', 0.4664325714111328),\n",
       " ('calamità', 0.45987528562545776),\n",
       " ('orrore', 0.4558510482311249),\n",
       " ('sbigottimento', 0.44617393612861633),\n",
       " ('raccapriccio', 0.43962791562080383),\n",
       " ('superstizioso', 0.4382532238960266),\n",
       " ('forsennato', 0.4303641617298126),\n",
       " ('carneficina', 0.43014198541641235),\n",
       " ('assalire', 0.42371997237205505)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v6.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2a67be2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v6.save(os.path.join('../trained_models/Word2Vec3', '3w2v6.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd33346",
   "metadata": {},
   "source": [
    "### Zeitraum 7: 1901-1925"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6c7fc2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text7 = ''\n",
    "\n",
    "for i in df7.lemmatized_text:\n",
    "    text7 += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a61dff94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 18.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences7 = tokenize_text(text7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "274ece89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v7 = Word2Vec(sentences=sentences7,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f97859ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sgomento', 0.5973503589630127),\n",
       " ('raccapriccio', 0.5805046558380127),\n",
       " ('orrore', 0.567000150680542),\n",
       " ('invincibile', 0.5637944340705872),\n",
       " ('subitaneo', 0.5500460863113403),\n",
       " ('spavento', 0.5416832566261292),\n",
       " ('smarrimento', 0.5412349700927734),\n",
       " ('straziante', 0.539233922958374),\n",
       " ('annichilire', 0.5364965200424194),\n",
       " ('gelare', 0.5324203968048096)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v7.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f3cec0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v7.save(os.path.join('../trained_models/Word2Vec3', '3w2v7.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54934b98",
   "metadata": {},
   "source": [
    "### Zeitraum 8: 1926-1950"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9f32ad8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text8 = ''\n",
    "\n",
    "for i in df8.lemmatized_text:\n",
    "    text8 += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "56c2283a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences8 = tokenize_text(text8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "20ed4b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v8 = Word2Vec(sentences=sentences8,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7a676dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rabbico', 0.6423127055168152),\n",
       " ('sgomento', 0.6386235952377319),\n",
       " ('virus', 0.6345242261886597),\n",
       " ('spavento', 0.6205704212188721),\n",
       " ('invasare', 0.6035366654396057),\n",
       " ('subitaneo', 0.5998023748397827),\n",
       " ('atterrire', 0.5904300808906555),\n",
       " ('tremito', 0.5899525284767151),\n",
       " ('stupore', 0.5891190767288208),\n",
       " ('furore', 0.5806159377098083)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v8.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c618a253",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v8.save(os.path.join('../trained_models/Word2Vec3', '3w2v8.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffecf4f1",
   "metadata": {},
   "source": [
    "### Zeitraum 9: 1951-1975"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "afe767d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text9 = ''\n",
    "\n",
    "for i in df9.lemmatized_text:\n",
    "    text9 += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0e4c1914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences9 = tokenize_text(text9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e840054a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v9 = Word2Vec(sentences=sentences9,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dad6d0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('orrore', 0.8980433344841003),\n",
       " ('maledizione', 0.8825047016143799),\n",
       " ('sconvolgere', 0.8749675750732422),\n",
       " ('disperazione', 0.8725539445877075),\n",
       " ('mortale', 0.8703424334526062),\n",
       " ('tremendo', 0.8663011193275452),\n",
       " ('impotente', 0.8552025556564331),\n",
       " ('immane', 0.8498296141624451),\n",
       " ('sventura', 0.8457055687904358),\n",
       " ('feroce', 0.8448697924613953)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v9.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1f840943",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v9.save(os.path.join('../trained_models/Word2Vec3', '3w2v9.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7eb5cd",
   "metadata": {},
   "source": [
    "### Zeitraum 10: 1976-2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b8d34fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text10 = ''\n",
    "\n",
    "for i in df10.lemmatized_text:\n",
    "    text10+= i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ed3d4cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 25.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences10 = tokenize_text(text10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "35c08bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v10 = Word2Vec(sentences=sentences10,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "60227ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('staliniano', 0.5717442631721497),\n",
       " ('terrorista', 0.5644408464431763),\n",
       " ('fondamentalista', 0.5635892152786255),\n",
       " ('sanguinario', 0.5524724721908569),\n",
       " ('terrorismo', 0.5483409762382507),\n",
       " ('incubo', 0.5468292832374573),\n",
       " ('autobomba', 0.5467087030410767),\n",
       " ('pol', 0.5458354353904724),\n",
       " ('deportazione', 0.5430185794830322),\n",
       " ('fanatico', 0.539924144744873)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v10.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e3c2b7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v10.save(os.path.join('../trained_models/Word2Vec3', '3w2v10.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54297223",
   "metadata": {},
   "source": [
    "### Zeitraum 11: 2001-2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2238429e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text11 = ''\n",
    "\n",
    "for i in df11.lemmatized_text:\n",
    "    text11+= i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c480ef84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 20.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences11 = tokenize_text(text11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b2b457e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v11 = Word2Vec(sentences=sentences11,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f0a144e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('orrore', 0.5889381170272827),\n",
       " ('oppressione', 0.5729219913482666),\n",
       " ('malvagità', 0.5616228580474854),\n",
       " ('atroce', 0.5597056746482849),\n",
       " ('barbarie', 0.5489183068275452),\n",
       " ('fanatismo', 0.5480705499649048),\n",
       " ('carestia', 0.5477238893508911),\n",
       " ('didi', 0.5462226867675781),\n",
       " ('carneficina', 0.5446843504905701),\n",
       " ('ceceno', 0.5436684489250183)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v11.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4e6a41fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v11.save(os.path.join('../trained_models/Word2Vec3', '3w2v11.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb8c247",
   "metadata": {},
   "source": [
    "### Zeitraum 12: 2011-2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2616fbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text12 = ''\n",
    "\n",
    "for i in df12.lemmatized_text:\n",
    "    text12+= i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9bb3ee56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 20.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences12 = tokenize_text(text12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6e729f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v12 = Word2Vec(sentences=sentences12,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a5df2993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ripiombare', 0.6142153143882751),\n",
       " ('incutere', 0.6073843240737915),\n",
       " ('odio', 0.5898599624633789),\n",
       " ('desolazione', 0.5756441354751587),\n",
       " ('cappa', 0.5743535757064819),\n",
       " ('seminare', 0.5727759003639221),\n",
       " ('sopraffazione', 0.5697144269943237),\n",
       " ('ferocia', 0.5689697861671448),\n",
       " ('sottomissione', 0.5672918558120728),\n",
       " ('plum', 0.5656874179840088)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v12.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4b2fc251",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v12.save(os.path.join('../trained_models/Word2Vec3', '3w2v12.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b0d1a1",
   "metadata": {},
   "source": [
    "### Zeitraum 13: 2017-2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "84be08f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text13 = ''\n",
    "\n",
    "for i in df13.lemmatized_text:\n",
    "    text13+= i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fbb3aec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 18.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences13 = tokenize_text(text13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7cb27594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v13 = Word2Vec(sentences=sentences13,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9b5f7cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('incutere', 0.6539342403411865),\n",
       " ('orrore', 0.6452838182449341),\n",
       " ('seminare', 0.628483235836029),\n",
       " ('impotenza', 0.6272907853126526),\n",
       " ('disorientamento', 0.6267272233963013),\n",
       " ('angoscia', 0.6199542880058289),\n",
       " ('paura', 0.6124224066734314),\n",
       " ('oppressione', 0.6107749342918396),\n",
       " ('frenesia', 0.6096921563148499),\n",
       " ('crudeltà', 0.6054523587226868)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v13.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "80953244",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v13.save(os.path.join('../trained_models/Word2Vec3', '3w2v13.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02105e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
