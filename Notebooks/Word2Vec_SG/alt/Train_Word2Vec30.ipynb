{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ba672df",
   "metadata": {},
   "source": [
    "# Trainingspipeline 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bb0ffc",
   "metadata": {},
   "source": [
    "- balanciertes Korpus\n",
    "- ohne Bigramme\n",
    "- vector_size: 300\n",
    "- window: 10\n",
    "- seed: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08e5260c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import nltk\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import scipy\n",
    "import spacy\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from joblib import Parallel, delayed  \n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09922b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stopwords.words('italian')\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/italian.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46f3e2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Korpus/Korpus/corpus_balanced.csv', sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d8fa580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>source</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>period</th>\n",
       "      <th>text_type</th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "      <th>lemmatized_text</th>\n",
       "      <th>cleaned_tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Poesia.IV.4.Testo.txt</td>\n",
       "      <td>MIDIA</td>\n",
       "      <td>Faustina Maratti Zappi</td>\n",
       "      <td>Poesie</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1700-1750</td>\n",
       "      <td>poesia</td>\n",
       "      <td>IV. 4. Rime degli Arcadi: Aglauro Cidonia (Fau...</td>\n",
       "      <td>3184.0</td>\n",
       "      <td>iv . 4 . rima del arcadi : aglauro cidonia ( f...</td>\n",
       "      <td>[['iv'], [], ['rima', 'arcadi', 'aglauro', 'ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Espositivi.IV.4.Testo.txt</td>\n",
       "      <td>MIDIA</td>\n",
       "      <td>Ludovico Antonio Muratori</td>\n",
       "      <td>Antichità italiane</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1700-1750</td>\n",
       "      <td>espositivo</td>\n",
       "      <td>﻿IV. 4. Ludovico Antonio Muratori, Antichità i...</td>\n",
       "      <td>8990.0</td>\n",
       "      <td>﻿iv . 4 . Ludovico Antonio muratori , antichit...</td>\n",
       "      <td>[['iv'], [], ['ludovico', 'antonio', 'muratori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Personali.IV.5.Testo.txt</td>\n",
       "      <td>MIDIA</td>\n",
       "      <td>Lorenzo Magalotti</td>\n",
       "      <td>Lettere odorose (1693-1705)</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1700-1750</td>\n",
       "      <td>personale</td>\n",
       "      <td>IV. 5. Lorenzo Magalotti, Lettere odorose (169...</td>\n",
       "      <td>8374.0</td>\n",
       "      <td>iv . 5 . Lorenzo magalotti , lettere odoroso (...</td>\n",
       "      <td>[['iv'], [], ['lorenzo', 'magalotti', 'lettere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Personali.IV.15.Testo.txt</td>\n",
       "      <td>MIDIA</td>\n",
       "      <td>Pietro Giannone</td>\n",
       "      <td>Vita scritta da lui medesimo</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1700-1750</td>\n",
       "      <td>personale</td>\n",
       "      <td>[Proemio]\\nPrendo a scrivere la mia vita e qua...</td>\n",
       "      <td>10118.0</td>\n",
       "      <td>[ proemio ] \\n prendere a scrivere il mio vita...</td>\n",
       "      <td>[['proemio', 'prendere', 'scrivere', 'vita', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Personali.IV.4.Testo.txt</td>\n",
       "      <td>MIDIA</td>\n",
       "      <td>Vincenzo da Filicaia</td>\n",
       "      <td>Lettere inedite a Lorenzo Magalotti</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1700-1750</td>\n",
       "      <td>personale</td>\n",
       "      <td>IV. 4. Vincenzo da Filicaia, Lettere inedite a...</td>\n",
       "      <td>10073.0</td>\n",
       "      <td>iv . 4 . Vincenzo da filicaia , lettere inedit...</td>\n",
       "      <td>[['iv'], [], ['vincenzo', 'filicaia', 'lettere...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         doc source                      author  \\\n",
       "0      Poesia.IV.4.Testo.txt  MIDIA      Faustina Maratti Zappi   \n",
       "1  Espositivi.IV.4.Testo.txt  MIDIA  Ludovico Antonio Muratori    \n",
       "2   Personali.IV.5.Testo.txt  MIDIA           Lorenzo Magalotti   \n",
       "3  Personali.IV.15.Testo.txt  MIDIA             Pietro Giannone   \n",
       "4   Personali.IV.4.Testo.txt  MIDIA        Vincenzo da Filicaia   \n",
       "\n",
       "                                 title    year     period   text_type  \\\n",
       "0                               Poesie  1700.0  1700-1750      poesia   \n",
       "1                   Antichità italiane  1700.0  1700-1750  espositivo   \n",
       "2          Lettere odorose (1693-1705)  1700.0  1700-1750   personale   \n",
       "3         Vita scritta da lui medesimo  1700.0  1700-1750   personale   \n",
       "4  Lettere inedite a Lorenzo Magalotti  1700.0  1700-1750   personale   \n",
       "\n",
       "                                                text    words  \\\n",
       "0  IV. 4. Rime degli Arcadi: Aglauro Cidonia (Fau...   3184.0   \n",
       "1  ﻿IV. 4. Ludovico Antonio Muratori, Antichità i...   8990.0   \n",
       "2  IV. 5. Lorenzo Magalotti, Lettere odorose (169...   8374.0   \n",
       "3  [Proemio]\\nPrendo a scrivere la mia vita e qua...  10118.0   \n",
       "4  IV. 4. Vincenzo da Filicaia, Lettere inedite a...  10073.0   \n",
       "\n",
       "                                     lemmatized_text  \\\n",
       "0  iv . 4 . rima del arcadi : aglauro cidonia ( f...   \n",
       "1  ﻿iv . 4 . Ludovico Antonio muratori , antichit...   \n",
       "2  iv . 5 . Lorenzo magalotti , lettere odoroso (...   \n",
       "3  [ proemio ] \\n prendere a scrivere il mio vita...   \n",
       "4  iv . 4 . Vincenzo da filicaia , lettere inedit...   \n",
       "\n",
       "                              cleaned_tokenized_text  \n",
       "0  [['iv'], [], ['rima', 'arcadi', 'aglauro', 'ci...  \n",
       "1  [['iv'], [], ['ludovico', 'antonio', 'muratori...  \n",
       "2  [['iv'], [], ['lorenzo', 'magalotti', 'lettere...  \n",
       "3  [['proemio', 'prendere', 'scrivere', 'vita', '...  \n",
       "4  [['iv'], [], ['vincenzo', 'filicaia', 'lettere...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d8d584b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(743763, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f02b06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.text = df.text.fillna('')\n",
    "df.lemmatized_text = df.lemmatized_text.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fea6e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einzeldataframes für die Zeiträume\n",
    "\n",
    "df_periods = dict(tuple(df.groupby(by='period')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea8a1150",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_periods['1700-1750']\n",
    "df2 = df_periods['1751-1800']\n",
    "df3 = df_periods['1801-1825']\n",
    "df4 = df_periods['1826-1850']\n",
    "df5 = df_periods['1851-1875']\n",
    "df6 = df_periods['1876-1900']\n",
    "df7 = df_periods['1901-1925']\n",
    "df8 = df_periods['1926-1950']\n",
    "df9 = df_periods['1951-1975']\n",
    "df10 = df_periods['1976-2000']\n",
    "df11 = df_periods['2001-2010']\n",
    "df12 = df_periods['2011-2016']\n",
    "df13 = df_periods['2017-2021']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "524c665b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>source</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>period</th>\n",
       "      <th>text_type</th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "      <th>lemmatized_text</th>\n",
       "      <th>cleaned_tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>126313</th>\n",
       "      <td>LISRodari3.txt</td>\n",
       "      <td>LIS</td>\n",
       "      <td>Gianno Rodari</td>\n",
       "      <td>La questione dei fumetti</td>\n",
       "      <td>1951.0</td>\n",
       "      <td>1951-1975</td>\n",
       "      <td>stampa</td>\n",
       "      <td>Caro Direttore , ho letto nell ' ultimo numero...</td>\n",
       "      <td>1510.0</td>\n",
       "      <td>caro direttore , avere leggere nell ' ultimo n...</td>\n",
       "      <td>[['caro', 'direttore', 'avere', 'leggere', 'ul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126314</th>\n",
       "      <td>LISJotti1.txt</td>\n",
       "      <td>LIS</td>\n",
       "      <td>Nilde Jotti</td>\n",
       "      <td>La questione dei fumetti</td>\n",
       "      <td>1951.0</td>\n",
       "      <td>1951-1975</td>\n",
       "      <td>stampa</td>\n",
       "      <td>Il dibattito sulla stampa a fumetti per i raga...</td>\n",
       "      <td>2785.0</td>\n",
       "      <td>il dibattito sulla stampa a fumetto per il rag...</td>\n",
       "      <td>[['dibattito', 'stampa', 'fumetto', 'ragazzo',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126315</th>\n",
       "      <td>LLAlbertelli1.txt</td>\n",
       "      <td>Liber Liber</td>\n",
       "      <td>Pilo Albertelli</td>\n",
       "      <td>Rousseau</td>\n",
       "      <td>1951.0</td>\n",
       "      <td>1951-1975</td>\n",
       "      <td>prosa letteraria</td>\n",
       "      <td>﻿Pilo Albertelli\\nRousseau\\n\\n  Nacque il 28 g...</td>\n",
       "      <td>4894.0</td>\n",
       "      <td>﻿pilo albertelli \\n rousseau \\n\\n   nascere il...</td>\n",
       "      <td>[['pilo', 'albertelli', 'rousseau', 'nascere',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126316</th>\n",
       "      <td>LISManacorda1.txt</td>\n",
       "      <td>LIS</td>\n",
       "      <td>Gastone Manacorda</td>\n",
       "      <td>Il Partito e la sua funzione di guida nel camp...</td>\n",
       "      <td>1951.0</td>\n",
       "      <td>1951-1975</td>\n",
       "      <td>stampa</td>\n",
       "      <td>Al partito , nel suo rigoglioso sviluppo , seg...</td>\n",
       "      <td>3460.0</td>\n",
       "      <td>al partito , nel suo rigoglioso sviluppo , seg...</td>\n",
       "      <td>[['partito', 'rigoglioso', 'sviluppo', 'seguit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126317</th>\n",
       "      <td>LISBianchi1.txt</td>\n",
       "      <td>LIS</td>\n",
       "      <td>Ranuccio Bianchi Bandinelli</td>\n",
       "      <td>Il nostro lavoro nella scuola</td>\n",
       "      <td>1951.0</td>\n",
       "      <td>1951-1975</td>\n",
       "      <td>stampa</td>\n",
       "      <td>Come in tutti i congressi , anche nel VII Cong...</td>\n",
       "      <td>2898.0</td>\n",
       "      <td>come in tutto il congresso , anche nel vii con...</td>\n",
       "      <td>[['congresso', 'vii', 'congresso', 'p'], ['tes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      doc       source                       author  \\\n",
       "126313     LISRodari3.txt          LIS                Gianno Rodari   \n",
       "126314      LISJotti1.txt          LIS                  Nilde Jotti   \n",
       "126315  LLAlbertelli1.txt  Liber Liber              Pilo Albertelli   \n",
       "126316  LISManacorda1.txt          LIS            Gastone Manacorda   \n",
       "126317    LISBianchi1.txt          LIS  Ranuccio Bianchi Bandinelli   \n",
       "\n",
       "                                                    title    year     period  \\\n",
       "126313                           La questione dei fumetti  1951.0  1951-1975   \n",
       "126314                           La questione dei fumetti  1951.0  1951-1975   \n",
       "126315                                           Rousseau  1951.0  1951-1975   \n",
       "126316  Il Partito e la sua funzione di guida nel camp...  1951.0  1951-1975   \n",
       "126317                     Il nostro lavoro nella scuola   1951.0  1951-1975   \n",
       "\n",
       "               text_type                                               text  \\\n",
       "126313            stampa  Caro Direttore , ho letto nell ' ultimo numero...   \n",
       "126314            stampa  Il dibattito sulla stampa a fumetti per i raga...   \n",
       "126315  prosa letteraria  ﻿Pilo Albertelli\\nRousseau\\n\\n  Nacque il 28 g...   \n",
       "126316            stampa  Al partito , nel suo rigoglioso sviluppo , seg...   \n",
       "126317            stampa  Come in tutti i congressi , anche nel VII Cong...   \n",
       "\n",
       "         words                                    lemmatized_text  \\\n",
       "126313  1510.0  caro direttore , avere leggere nell ' ultimo n...   \n",
       "126314  2785.0  il dibattito sulla stampa a fumetto per il rag...   \n",
       "126315  4894.0  ﻿pilo albertelli \\n rousseau \\n\\n   nascere il...   \n",
       "126316  3460.0  al partito , nel suo rigoglioso sviluppo , seg...   \n",
       "126317  2898.0  come in tutto il congresso , anche nel vii con...   \n",
       "\n",
       "                                   cleaned_tokenized_text  \n",
       "126313  [['caro', 'direttore', 'avere', 'leggere', 'ul...  \n",
       "126314  [['dibattito', 'stampa', 'fumetto', 'ragazzo',...  \n",
       "126315  [['pilo', 'albertelli', 'rousseau', 'nascere',...  \n",
       "126316  [['partito', 'rigoglioso', 'sviluppo', 'seguit...  \n",
       "126317  [['congresso', 'vii', 'congresso', 'p'], ['tes...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df9.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8298b52a",
   "metadata": {},
   "source": [
    "## Training von Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44b8d2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hilfsfunktionen zur Vorbereitung auf das Training\n",
    "# Bereinigung und Tokenisierung\n",
    "\n",
    "def sentence_to_wordlist(raw:str):\n",
    "    \"\"\"\n",
    "    cleans and tokenizes the sentences\n",
    "    \"\"\"\n",
    "    text = re.sub('[^A-Za-z_àÀèÈìÌòÒùÙáÁéÉíÍóÓúÚ]',' ', raw).split()        # Diakritika ans Italienische anpassen                    \n",
    "    filtered_text = [word for word in text if word not in stopwords]        # Stopwörter löschen\n",
    "    return filtered_text\n",
    "\n",
    "\n",
    "def tokenize_text(raw_text):\n",
    "    \"\"\"\n",
    "    returns a list of lowercase tokenized sentences \n",
    "    \"\"\"\n",
    "    raw_sentences = tokenizer.tokenize(str(raw_text).lower())    \n",
    "    tokenized_sentences = Parallel(n_jobs=-1)(delayed(sentence_to_wordlist)(raw_sentence) for raw_sentence in raw_sentences)\n",
    "    sentences = tokenized_sentences\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "167dbe44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainingsparamter setzen\n",
    "\n",
    "vector_size = 300                  # Dimensionality of the word vectors\n",
    "window = 10                        # The maximum distance between the current and predicted word within a sentence\n",
    "min_count = 2                      # (int, optional) – The model ignores all words with total frequency lower than this\n",
    "workers = 1                        # Use these many worker threads to train the model (faster training with multicore machines)\n",
    "min_alpha = 0.0001                 # Learning rate will linearly drop to min_alpha as training progresses\n",
    "sg = 1                             # Training algorithm: skip-gram if sg=1, otherwise CBOW            \n",
    "seed = 1                           # Reproductivity --> only if workers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cab9952f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordner anlegen zum Abspeichern von trainierten Modellen\n",
    "\n",
    "if not os.path.exists('../trained_models'):\n",
    "    os.makedirs('../trained_models')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8d041b",
   "metadata": {},
   "source": [
    "### Zeitraum 1: 1700-1750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a28475c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatisierte Texte zu einem String verbinden\n",
    "\n",
    "text1 = ''\n",
    "\n",
    "for i in df1.lemmatized_text:\n",
    "    text1 += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd305b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 21.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences1 = tokenize_text(text1)         # Bereinigen, Tokenisieren und in Form bringen (Ziel: Liste von tokenisierten Sätzen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f3bbf96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Training   \n",
    "\n",
    "w2v1 = Word2Vec(sentences=sentences1,                      \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac18caca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lodigiano', 0.5615582466125488),\n",
       " ('costernazione', 0.5529147982597351),\n",
       " ('spavento', 0.5432156324386597),\n",
       " ('turchesche', 0.5418321490287781),\n",
       " ('riempiè', 0.5404583811759949),\n",
       " ('implacabilità', 0.5221208333969116),\n",
       " ('avanzò', 0.5218067765235901),\n",
       " ('alviano', 0.5214826464653015),\n",
       " ('impadronitosi', 0.5132208466529846),\n",
       " ('barbari', 0.5108266472816467)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v1.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddba9921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainiertes Modell speichern\n",
    "\n",
    "w2v1.save(os.path.join('../trained_models/Word2Vec30', '30w2v1.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd3a0bc",
   "metadata": {},
   "source": [
    "### Zeitraum 2: 1751-1800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f4c26d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = ''\n",
    "\n",
    "for i in df2.lemmatized_text:\n",
    "    text2 += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eaa2b3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 25.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences2 = tokenize_text(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ee58cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v2 = Word2Vec(sentences=sentences2,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f2382df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('formidabil', 0.614395797252655),\n",
       " ('ostile', 0.6111111044883728),\n",
       " ('crociati', 0.5993159413337708),\n",
       " ('timur', 0.5929927229881287),\n",
       " ('inspirare', 0.5877782106399536),\n",
       " ('legione', 0.5870984792709351),\n",
       " ('devastazione', 0.5841709971427917),\n",
       " ('avvicinarsi', 0.5518136620521545),\n",
       " ('avversione', 0.5478644371032715),\n",
       " ('tribù', 0.5423879027366638)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v2.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "912ce604",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v2.save(os.path.join('../trained_models/Word2Vec30', '30w2v2.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12799bcb",
   "metadata": {},
   "source": [
    "### Zeitraum 3: 1801-1825"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "31895854",
   "metadata": {},
   "outputs": [],
   "source": [
    "text3 = ''\n",
    "\n",
    "for i in df3.lemmatized_text:\n",
    "    text3 += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b20f1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 22.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences3 = tokenize_text(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f33cd50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v3 = Word2Vec(sentences=sentences3,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc887350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('repentino', 0.700520396232605),\n",
       " ('sovrannaturale', 0.6435088515281677),\n",
       " ('aspettò', 0.6315177083015442),\n",
       " ('fremè', 0.6243984699249268),\n",
       " ('impadronisce', 0.6171139478683472),\n",
       " ('sorpresa', 0.6126025319099426),\n",
       " ('innalza', 0.6068622469902039),\n",
       " ('imaginari', 0.5984677672386169),\n",
       " ('rammarico', 0.5919321775436401),\n",
       " ('abbattimento', 0.5886495113372803)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v3.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6a8e8201",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v3.save(os.path.join('../trained_models/Word2Vec30', '30w2v3.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7ad1fa",
   "metadata": {},
   "source": [
    "### Zeitraum 4: 1826-1850"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dfc8abc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text4 = ''\n",
    "\n",
    "for i in df4.lemmatized_text:\n",
    "    text4 += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d304d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 21.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences4 = tokenize_text(text4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0186858c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v4 = Word2Vec(sentences=sentences4,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6985b1e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('panico', 0.543762743473053),\n",
       " ('bentosto', 0.5170122981071472),\n",
       " ('inspirare', 0.5107207894325256),\n",
       " ('villetard', 0.482183039188385),\n",
       " ('riurto', 0.47408032417297363),\n",
       " ('scompiglio', 0.4709429442882538),\n",
       " ('dissipare', 0.46923819184303284),\n",
       " ('accostava', 0.4678434729576111),\n",
       " ('incusso', 0.4651920199394226),\n",
       " ('aristocrazìa', 0.4642694294452667)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v4.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "33c0263d",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v4.save(os.path.join('../trained_models/Word2Vec30', '30w2v4.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adbc52f",
   "metadata": {},
   "source": [
    "### Zeitraum 5: 1851-1875"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "14f4f694",
   "metadata": {},
   "outputs": [],
   "source": [
    "text5 = ''\n",
    "\n",
    "for i in df5.lemmatized_text:\n",
    "    text5 += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a37ae9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 23.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences5 = tokenize_text(text5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "14e061e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v5 = Word2Vec(sentences=sentences5,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5dcf457a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sgomento', 0.5722348690032959),\n",
       " ('spavento', 0.54362952709198),\n",
       " ('orrore', 0.5253002643585205),\n",
       " ('rabbia', 0.5158381462097168),\n",
       " ('gioja', 0.5135176181793213),\n",
       " ('rammarichío', 0.5075597763061523),\n",
       " ('raccapriccio', 0.5061434507369995),\n",
       " ('tradito', 0.5018460750579834),\n",
       " ('agonia', 0.4989558458328247),\n",
       " ('atterriti', 0.4980342984199524)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v5.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "890b9950",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v5.save(os.path.join('../trained_models/Word2Vec30', '30w2v5.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8264d8",
   "metadata": {},
   "source": [
    "### Zeitraum 6: 1876-1900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3602dbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text6 = ''\n",
    "\n",
    "for i in df6.lemmatized_text:\n",
    "    text6 += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e68bdf54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 26.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences6 = tokenize_text(text6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "396efd17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v6 = Word2Vec(sentences=sentences6,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ee88f9b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spavento', 0.49233606457710266),\n",
       " ('sgomento', 0.4664325714111328),\n",
       " ('calamità', 0.45987528562545776),\n",
       " ('orrore', 0.4558510482311249),\n",
       " ('sbigottimento', 0.44617393612861633),\n",
       " ('raccapriccio', 0.43962791562080383),\n",
       " ('superstizioso', 0.4382532238960266),\n",
       " ('forsennato', 0.4303641617298126),\n",
       " ('carneficina', 0.43014198541641235),\n",
       " ('assalire', 0.42371997237205505)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v6.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2a67be2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v6.save(os.path.join('../trained_models/Word2Vec30', '30w2v6.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd33346",
   "metadata": {},
   "source": [
    "### Zeitraum 7: 1901-1925"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6c7fc2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text7 = ''\n",
    "\n",
    "for i in df7.lemmatized_text:\n",
    "    text7 += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a61dff94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 27.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences7 = tokenize_text(text7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "274ece89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v7 = Word2Vec(sentences=sentences7,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f97859ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gelare', 0.4697500169277191),\n",
       " ('smarrimento', 0.4620377719402313),\n",
       " ('ribrezzo', 0.46144673228263855),\n",
       " ('orrore', 0.46043723821640015),\n",
       " ('selvaggiamente', 0.4515904486179352),\n",
       " ('sbalordimento', 0.4502129554748535),\n",
       " ('giovanezza', 0.4491518437862396),\n",
       " ('inopinatamente', 0.4482017755508423),\n",
       " ('sfuggito', 0.4477081596851349),\n",
       " ('accesso', 0.44765958189964294)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v7.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f3cec0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v7.save(os.path.join('../trained_models/Word2Vec30', '30w2v7.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54934b98",
   "metadata": {},
   "source": [
    "### Zeitraum 8: 1926-1950"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9f32ad8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text8 = ''\n",
    "\n",
    "for i in df8.lemmatized_text:\n",
    "    text8 += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "56c2283a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 24.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences8 = tokenize_text(text8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "20ed4b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v8 = Word2Vec(sentences=sentences8,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7a676dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rabbico', 0.562032163143158),\n",
       " ('virus', 0.5619686841964722),\n",
       " ('paralizzare', 0.4947842061519623),\n",
       " ('frammettendosi', 0.4936181306838989),\n",
       " ('innestato', 0.49003320932388306),\n",
       " ('impietrire', 0.48735207319259644),\n",
       " ('semispento', 0.48045191168785095),\n",
       " ('soffocandomi', 0.47972235083580017),\n",
       " ('pettirosso', 0.47964251041412354),\n",
       " ('conversa', 0.4790685772895813)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v8.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c618a253",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v8.save(os.path.join('../trained_models/Word2Vec30', '30w2v8.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffecf4f1",
   "metadata": {},
   "source": [
    "### Zeitraum 9: 1951-1975"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "afe767d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text9 = ''\n",
    "\n",
    "for i in df9.lemmatized_text:\n",
    "    text9 += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0e4c1914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 25.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences9 = tokenize_text(text9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e840054a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v9 = Word2Vec(sentences=sentences9,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dad6d0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('malefico', 0.6287841796875),\n",
       " ('insano', 0.6057776212692261),\n",
       " ('spasmodicamente', 0.604286253452301),\n",
       " ('orrore', 0.6025545001029968),\n",
       " ('assopita', 0.5936296582221985),\n",
       " ('raccapriccio', 0.5830296277999878),\n",
       " ('smarrimento', 0.5782256722450256),\n",
       " ('inorridito', 0.5777332186698914),\n",
       " ('lussuria', 0.5761638283729553),\n",
       " ('opprime', 0.5701215267181396)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v9.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1f840943",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v9.save(os.path.join('../trained_models/Word2Vec30', '30w2v9.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7eb5cd",
   "metadata": {},
   "source": [
    "### Zeitraum 10: 1976-2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b8d34fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text10 = ''\n",
    "\n",
    "for i in df10.lemmatized_text:\n",
    "    text10+= i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ed3d4cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 28.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences10 = tokenize_text(text10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "35c08bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v10 = Word2Vec(sentences=sentences10,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "60227ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('staliniano', 0.5717442631721497),\n",
       " ('terrorista', 0.5644408464431763),\n",
       " ('fondamentalista', 0.5635892152786255),\n",
       " ('sanguinario', 0.5524724721908569),\n",
       " ('terrorismo', 0.5483409762382507),\n",
       " ('incubo', 0.5468292832374573),\n",
       " ('autobomba', 0.5467087030410767),\n",
       " ('pol', 0.5458354353904724),\n",
       " ('deportazione', 0.5430185794830322),\n",
       " ('fanatico', 0.539924144744873)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v10.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e3c2b7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v10.save(os.path.join('../trained_models/Word2Vec30', '30w2v10.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54297223",
   "metadata": {},
   "source": [
    "### Zeitraum 11: 2001-2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2238429e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text11 = ''\n",
    "\n",
    "for i in df11.lemmatized_text:\n",
    "    text11+= i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c480ef84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 22.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences11 = tokenize_text(text11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b2b457e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v11 = Word2Vec(sentences=sentences11,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f0a144e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('orrore', 0.5889381170272827),\n",
       " ('oppressione', 0.5729219913482666),\n",
       " ('malvagità', 0.5616228580474854),\n",
       " ('atroce', 0.5597056746482849),\n",
       " ('barbarie', 0.5489183068275452),\n",
       " ('fanatismo', 0.5480705499649048),\n",
       " ('carestia', 0.5477238893508911),\n",
       " ('didi', 0.5462226867675781),\n",
       " ('carneficina', 0.5446843504905701),\n",
       " ('ceceno', 0.5436684489250183)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v11.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4e6a41fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v11.save(os.path.join('../trained_models/Word2Vec30', '30w2v11.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb8c247",
   "metadata": {},
   "source": [
    "### Zeitraum 12: 2011-2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2616fbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text12 = ''\n",
    "\n",
    "for i in df12.lemmatized_text:\n",
    "    text12+= i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9bb3ee56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 20.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences12 = tokenize_text(text12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6e729f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v12 = Word2Vec(sentences=sentences12,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a5df2993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ripiombare', 0.6142153143882751),\n",
       " ('incutere', 0.6073843240737915),\n",
       " ('odio', 0.5898599624633789),\n",
       " ('desolazione', 0.5756441354751587),\n",
       " ('cappa', 0.5743535757064819),\n",
       " ('seminare', 0.5727759003639221),\n",
       " ('sopraffazione', 0.5697144269943237),\n",
       " ('ferocia', 0.5689697861671448),\n",
       " ('sottomissione', 0.5672918558120728),\n",
       " ('plum', 0.5656874179840088)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v12.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4b2fc251",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v12.save(os.path.join('../trained_models/Word2Vec30', '30w2v12.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b0d1a1",
   "metadata": {},
   "source": [
    "### Zeitraum 13: 2017-2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "84be08f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text13 = ''\n",
    "\n",
    "for i in df13.lemmatized_text:\n",
    "    text13+= i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fbb3aec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 18.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences13 = tokenize_text(text13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7cb27594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v13 = Word2Vec(sentences=sentences13,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9b5f7cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('incutere', 0.6539342403411865),\n",
       " ('orrore', 0.6452838182449341),\n",
       " ('seminare', 0.628483235836029),\n",
       " ('impotenza', 0.6272907853126526),\n",
       " ('disorientamento', 0.6267272233963013),\n",
       " ('angoscia', 0.6199542880058289),\n",
       " ('paura', 0.6124224066734314),\n",
       " ('oppressione', 0.6107749342918396),\n",
       " ('frenesia', 0.6096921563148499),\n",
       " ('crudeltà', 0.6054523587226868)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v13.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "80953244",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v13.save(os.path.join('../trained_models/Word2Vec30', '30w2v13.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02105e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
