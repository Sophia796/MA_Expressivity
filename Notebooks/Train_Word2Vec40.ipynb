{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ba672df",
   "metadata": {},
   "source": [
    "# Trainingspipeline 40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bb0ffc",
   "metadata": {},
   "source": [
    "- balanciertes Korpus\n",
    "- ohne Bigramme\n",
    "- vector_size: 300\n",
    "- window: 15\n",
    "- seed: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08e5260c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import nltk\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import scipy\n",
    "import spacy\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from joblib import Parallel, delayed  \n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09922b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stopwords.words('italian')\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/italian.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46f3e2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Korpus/Korpus/corpus_balanced.csv', sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d8fa580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>source</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>period</th>\n",
       "      <th>text_type</th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "      <th>lemmatized_text</th>\n",
       "      <th>cleaned_tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Poesia.IV.4.Testo.txt</td>\n",
       "      <td>MIDIA</td>\n",
       "      <td>Faustina Maratti Zappi</td>\n",
       "      <td>Poesie</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1700-1750</td>\n",
       "      <td>poesia</td>\n",
       "      <td>IV. 4. Rime degli Arcadi: Aglauro Cidonia (Fau...</td>\n",
       "      <td>3184.0</td>\n",
       "      <td>iv . 4 . rima del arcadi : aglauro cidonia ( f...</td>\n",
       "      <td>[['iv'], [], ['rima', 'arcadi', 'aglauro', 'ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Espositivi.IV.4.Testo.txt</td>\n",
       "      <td>MIDIA</td>\n",
       "      <td>Ludovico Antonio Muratori</td>\n",
       "      <td>Antichità italiane</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1700-1750</td>\n",
       "      <td>espositivo</td>\n",
       "      <td>﻿IV. 4. Ludovico Antonio Muratori, Antichità i...</td>\n",
       "      <td>8990.0</td>\n",
       "      <td>﻿iv . 4 . Ludovico Antonio muratori , antichit...</td>\n",
       "      <td>[['iv'], [], ['ludovico', 'antonio', 'muratori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Personali.IV.5.Testo.txt</td>\n",
       "      <td>MIDIA</td>\n",
       "      <td>Lorenzo Magalotti</td>\n",
       "      <td>Lettere odorose (1693-1705)</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1700-1750</td>\n",
       "      <td>personale</td>\n",
       "      <td>IV. 5. Lorenzo Magalotti, Lettere odorose (169...</td>\n",
       "      <td>8374.0</td>\n",
       "      <td>iv . 5 . Lorenzo magalotti , lettere odoroso (...</td>\n",
       "      <td>[['iv'], [], ['lorenzo', 'magalotti', 'lettere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Personali.IV.15.Testo.txt</td>\n",
       "      <td>MIDIA</td>\n",
       "      <td>Pietro Giannone</td>\n",
       "      <td>Vita scritta da lui medesimo</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1700-1750</td>\n",
       "      <td>personale</td>\n",
       "      <td>[Proemio]\\nPrendo a scrivere la mia vita e qua...</td>\n",
       "      <td>10118.0</td>\n",
       "      <td>[ proemio ] \\n prendere a scrivere il mio vita...</td>\n",
       "      <td>[['proemio', 'prendere', 'scrivere', 'vita', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Personali.IV.4.Testo.txt</td>\n",
       "      <td>MIDIA</td>\n",
       "      <td>Vincenzo da Filicaia</td>\n",
       "      <td>Lettere inedite a Lorenzo Magalotti</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1700-1750</td>\n",
       "      <td>personale</td>\n",
       "      <td>IV. 4. Vincenzo da Filicaia, Lettere inedite a...</td>\n",
       "      <td>10073.0</td>\n",
       "      <td>iv . 4 . Vincenzo da filicaia , lettere inedit...</td>\n",
       "      <td>[['iv'], [], ['vincenzo', 'filicaia', 'lettere...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         doc source                      author  \\\n",
       "0      Poesia.IV.4.Testo.txt  MIDIA      Faustina Maratti Zappi   \n",
       "1  Espositivi.IV.4.Testo.txt  MIDIA  Ludovico Antonio Muratori    \n",
       "2   Personali.IV.5.Testo.txt  MIDIA           Lorenzo Magalotti   \n",
       "3  Personali.IV.15.Testo.txt  MIDIA             Pietro Giannone   \n",
       "4   Personali.IV.4.Testo.txt  MIDIA        Vincenzo da Filicaia   \n",
       "\n",
       "                                 title    year     period   text_type  \\\n",
       "0                               Poesie  1700.0  1700-1750      poesia   \n",
       "1                   Antichità italiane  1700.0  1700-1750  espositivo   \n",
       "2          Lettere odorose (1693-1705)  1700.0  1700-1750   personale   \n",
       "3         Vita scritta da lui medesimo  1700.0  1700-1750   personale   \n",
       "4  Lettere inedite a Lorenzo Magalotti  1700.0  1700-1750   personale   \n",
       "\n",
       "                                                text    words  \\\n",
       "0  IV. 4. Rime degli Arcadi: Aglauro Cidonia (Fau...   3184.0   \n",
       "1  ﻿IV. 4. Ludovico Antonio Muratori, Antichità i...   8990.0   \n",
       "2  IV. 5. Lorenzo Magalotti, Lettere odorose (169...   8374.0   \n",
       "3  [Proemio]\\nPrendo a scrivere la mia vita e qua...  10118.0   \n",
       "4  IV. 4. Vincenzo da Filicaia, Lettere inedite a...  10073.0   \n",
       "\n",
       "                                     lemmatized_text  \\\n",
       "0  iv . 4 . rima del arcadi : aglauro cidonia ( f...   \n",
       "1  ﻿iv . 4 . Ludovico Antonio muratori , antichit...   \n",
       "2  iv . 5 . Lorenzo magalotti , lettere odoroso (...   \n",
       "3  [ proemio ] \\n prendere a scrivere il mio vita...   \n",
       "4  iv . 4 . Vincenzo da filicaia , lettere inedit...   \n",
       "\n",
       "                              cleaned_tokenized_text  \n",
       "0  [['iv'], [], ['rima', 'arcadi', 'aglauro', 'ci...  \n",
       "1  [['iv'], [], ['ludovico', 'antonio', 'muratori...  \n",
       "2  [['iv'], [], ['lorenzo', 'magalotti', 'lettere...  \n",
       "3  [['proemio', 'prendere', 'scrivere', 'vita', '...  \n",
       "4  [['iv'], [], ['vincenzo', 'filicaia', 'lettere...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d8d584b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(743763, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f02b06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.text = df.text.fillna('')\n",
    "df.lemmatized_text = df.lemmatized_text.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fea6e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einzeldataframes für die Zeiträume\n",
    "\n",
    "df_periods = dict(tuple(df.groupby(by='period')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea8a1150",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_periods['1700-1750']\n",
    "df2 = df_periods['1751-1800']\n",
    "df3 = df_periods['1801-1825']\n",
    "df4 = df_periods['1826-1850']\n",
    "df5 = df_periods['1851-1875']\n",
    "df6 = df_periods['1876-1900']\n",
    "df7 = df_periods['1901-1925']\n",
    "df8 = df_periods['1926-1950']\n",
    "df9 = df_periods['1951-1975']\n",
    "df10 = df_periods['1976-2000']\n",
    "df11 = df_periods['2001-2010']\n",
    "df12 = df_periods['2011-2016']\n",
    "df13 = df_periods['2017-2021']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "524c665b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>source</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>period</th>\n",
       "      <th>text_type</th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "      <th>lemmatized_text</th>\n",
       "      <th>cleaned_tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>126313</th>\n",
       "      <td>LISRodari3.txt</td>\n",
       "      <td>LIS</td>\n",
       "      <td>Gianno Rodari</td>\n",
       "      <td>La questione dei fumetti</td>\n",
       "      <td>1951.0</td>\n",
       "      <td>1951-1975</td>\n",
       "      <td>stampa</td>\n",
       "      <td>Caro Direttore , ho letto nell ' ultimo numero...</td>\n",
       "      <td>1510.0</td>\n",
       "      <td>caro direttore , avere leggere nell ' ultimo n...</td>\n",
       "      <td>[['caro', 'direttore', 'avere', 'leggere', 'ul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126314</th>\n",
       "      <td>LISJotti1.txt</td>\n",
       "      <td>LIS</td>\n",
       "      <td>Nilde Jotti</td>\n",
       "      <td>La questione dei fumetti</td>\n",
       "      <td>1951.0</td>\n",
       "      <td>1951-1975</td>\n",
       "      <td>stampa</td>\n",
       "      <td>Il dibattito sulla stampa a fumetti per i raga...</td>\n",
       "      <td>2785.0</td>\n",
       "      <td>il dibattito sulla stampa a fumetto per il rag...</td>\n",
       "      <td>[['dibattito', 'stampa', 'fumetto', 'ragazzo',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126315</th>\n",
       "      <td>LLAlbertelli1.txt</td>\n",
       "      <td>Liber Liber</td>\n",
       "      <td>Pilo Albertelli</td>\n",
       "      <td>Rousseau</td>\n",
       "      <td>1951.0</td>\n",
       "      <td>1951-1975</td>\n",
       "      <td>prosa letteraria</td>\n",
       "      <td>﻿Pilo Albertelli\\nRousseau\\n\\n  Nacque il 28 g...</td>\n",
       "      <td>4894.0</td>\n",
       "      <td>﻿pilo albertelli \\n rousseau \\n\\n   nascere il...</td>\n",
       "      <td>[['pilo', 'albertelli', 'rousseau', 'nascere',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126316</th>\n",
       "      <td>LISManacorda1.txt</td>\n",
       "      <td>LIS</td>\n",
       "      <td>Gastone Manacorda</td>\n",
       "      <td>Il Partito e la sua funzione di guida nel camp...</td>\n",
       "      <td>1951.0</td>\n",
       "      <td>1951-1975</td>\n",
       "      <td>stampa</td>\n",
       "      <td>Al partito , nel suo rigoglioso sviluppo , seg...</td>\n",
       "      <td>3460.0</td>\n",
       "      <td>al partito , nel suo rigoglioso sviluppo , seg...</td>\n",
       "      <td>[['partito', 'rigoglioso', 'sviluppo', 'seguit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126317</th>\n",
       "      <td>LISBianchi1.txt</td>\n",
       "      <td>LIS</td>\n",
       "      <td>Ranuccio Bianchi Bandinelli</td>\n",
       "      <td>Il nostro lavoro nella scuola</td>\n",
       "      <td>1951.0</td>\n",
       "      <td>1951-1975</td>\n",
       "      <td>stampa</td>\n",
       "      <td>Come in tutti i congressi , anche nel VII Cong...</td>\n",
       "      <td>2898.0</td>\n",
       "      <td>come in tutto il congresso , anche nel vii con...</td>\n",
       "      <td>[['congresso', 'vii', 'congresso', 'p'], ['tes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      doc       source                       author  \\\n",
       "126313     LISRodari3.txt          LIS                Gianno Rodari   \n",
       "126314      LISJotti1.txt          LIS                  Nilde Jotti   \n",
       "126315  LLAlbertelli1.txt  Liber Liber              Pilo Albertelli   \n",
       "126316  LISManacorda1.txt          LIS            Gastone Manacorda   \n",
       "126317    LISBianchi1.txt          LIS  Ranuccio Bianchi Bandinelli   \n",
       "\n",
       "                                                    title    year     period  \\\n",
       "126313                           La questione dei fumetti  1951.0  1951-1975   \n",
       "126314                           La questione dei fumetti  1951.0  1951-1975   \n",
       "126315                                           Rousseau  1951.0  1951-1975   \n",
       "126316  Il Partito e la sua funzione di guida nel camp...  1951.0  1951-1975   \n",
       "126317                     Il nostro lavoro nella scuola   1951.0  1951-1975   \n",
       "\n",
       "               text_type                                               text  \\\n",
       "126313            stampa  Caro Direttore , ho letto nell ' ultimo numero...   \n",
       "126314            stampa  Il dibattito sulla stampa a fumetti per i raga...   \n",
       "126315  prosa letteraria  ﻿Pilo Albertelli\\nRousseau\\n\\n  Nacque il 28 g...   \n",
       "126316            stampa  Al partito , nel suo rigoglioso sviluppo , seg...   \n",
       "126317            stampa  Come in tutti i congressi , anche nel VII Cong...   \n",
       "\n",
       "         words                                    lemmatized_text  \\\n",
       "126313  1510.0  caro direttore , avere leggere nell ' ultimo n...   \n",
       "126314  2785.0  il dibattito sulla stampa a fumetto per il rag...   \n",
       "126315  4894.0  ﻿pilo albertelli \\n rousseau \\n\\n   nascere il...   \n",
       "126316  3460.0  al partito , nel suo rigoglioso sviluppo , seg...   \n",
       "126317  2898.0  come in tutto il congresso , anche nel vii con...   \n",
       "\n",
       "                                   cleaned_tokenized_text  \n",
       "126313  [['caro', 'direttore', 'avere', 'leggere', 'ul...  \n",
       "126314  [['dibattito', 'stampa', 'fumetto', 'ragazzo',...  \n",
       "126315  [['pilo', 'albertelli', 'rousseau', 'nascere',...  \n",
       "126316  [['partito', 'rigoglioso', 'sviluppo', 'seguit...  \n",
       "126317  [['congresso', 'vii', 'congresso', 'p'], ['tes...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df9.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8298b52a",
   "metadata": {},
   "source": [
    "## Training von Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44b8d2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hilfsfunktionen zur Vorbereitung auf das Training\n",
    "# Bereinigung und Tokenisierung\n",
    "\n",
    "def sentence_to_wordlist(raw:str):\n",
    "    \"\"\"\n",
    "    cleans and tokenizes the sentences\n",
    "    \"\"\"\n",
    "    text = re.sub('[^A-Za-z_àÀèÈìÌòÒùÙáÁéÉíÍóÓúÚ]',' ', raw).split()        # Diakritika ans Italienische anpassen                    \n",
    "    filtered_text = [word for word in text if word not in stopwords]        # Stopwörter löschen\n",
    "    return filtered_text\n",
    "\n",
    "\n",
    "def tokenize_text(raw_text):\n",
    "    \"\"\"\n",
    "    returns a list of lowercase tokenized sentences \n",
    "    \"\"\"\n",
    "    raw_sentences = tokenizer.tokenize(str(raw_text).lower())    \n",
    "    tokenized_sentences = Parallel(n_jobs=-1)(delayed(sentence_to_wordlist)(raw_sentence) for raw_sentence in raw_sentences)\n",
    "    sentences = tokenized_sentences\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "167dbe44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainingsparamter setzen\n",
    "\n",
    "vector_size = 300                  # Dimensionality of the word vectors\n",
    "window = 15                        # The maximum distance between the current and predicted word within a sentence\n",
    "min_count = 2                      # (int, optional) – The model ignores all words with total frequency lower than this\n",
    "workers = 1                        # Use these many worker threads to train the model (faster training with multicore machines)\n",
    "min_alpha = 0.0001                 # Learning rate will linearly drop to min_alpha as training progresses\n",
    "sg = 1                             # Training algorithm: skip-gram if sg=1, otherwise CBOW            \n",
    "seed = 1                           # Reproductivity --> only if workers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cab9952f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordner anlegen zum Abspeichern von trainierten Modellen\n",
    "\n",
    "if not os.path.exists('../trained_models'):\n",
    "    os.makedirs('../trained_models')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8d041b",
   "metadata": {},
   "source": [
    "### Zeitraum 1: 1700-1750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a28475c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatisierte Texte zu einem String verbinden\n",
    "\n",
    "text1 = ''\n",
    "\n",
    "for i in df1.lemmatized_text:\n",
    "    text1 += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd305b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 21.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences1 = tokenize_text(text1)         # Bereinigen, Tokenisieren und in Form bringen (Ziel: Liste von tokenisierten Sätzen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f3bbf96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Training   \n",
    "\n",
    "w2v1 = Word2Vec(sentences=sentences1,                      \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac18caca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('turchesche', 0.5449481010437012),\n",
       " ('lodigiano', 0.53666090965271),\n",
       " ('avanzò', 0.5358530879020691),\n",
       " ('bavaresi', 0.5295931100845337),\n",
       " ('riempiè', 0.527573823928833),\n",
       " ('commozione', 0.5225040316581726),\n",
       " ('carmagnola', 0.5209928154945374),\n",
       " ('spavento', 0.5143598914146423),\n",
       " ('impadronitosi', 0.5131425261497498),\n",
       " ('costernazione', 0.5126888751983643)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v1.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddba9921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainiertes Modell speichern\n",
    "\n",
    "w2v1.save(os.path.join('../trained_models/Word2Vec40', '40w2v1.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd3a0bc",
   "metadata": {},
   "source": [
    "### Zeitraum 2: 1751-1800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f4c26d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = ''\n",
    "\n",
    "for i in df2.lemmatized_text:\n",
    "    text2 += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eaa2b3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 30.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences2 = tokenize_text(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ee58cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v2 = Word2Vec(sentences=sentences2,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f2382df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ostile', 0.6011592149734497),\n",
       " ('timur', 0.596372663974762),\n",
       " ('inspirare', 0.5947270393371582),\n",
       " ('legione', 0.5836865305900574),\n",
       " ('agghiadando', 0.5806405544281006),\n",
       " ('crociati', 0.5787096619606018),\n",
       " ('devastazione', 0.5780643224716187),\n",
       " ('formidabil', 0.5735940933227539),\n",
       " ('invisibili', 0.5637351870536804),\n",
       " ('secondarono', 0.5532472133636475)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v2.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "912ce604",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v2.save(os.path.join('../trained_models/Word2Vec40', '40w2v2.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12799bcb",
   "metadata": {},
   "source": [
    "### Zeitraum 3: 1801-1825"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "31895854",
   "metadata": {},
   "outputs": [],
   "source": [
    "text3 = ''\n",
    "\n",
    "for i in df3.lemmatized_text:\n",
    "    text3 += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b20f1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 26.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences3 = tokenize_text(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f33cd50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v3 = Word2Vec(sentences=sentences3,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc887350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('repentino', 0.6435782313346863),\n",
       " ('fremè', 0.6033051609992981),\n",
       " ('impadronisce', 0.5937840938568115),\n",
       " ('aspettò', 0.5876455307006836),\n",
       " ('imaginari', 0.5873774290084839),\n",
       " ('sovrannaturale', 0.5851864814758301),\n",
       " ('innalza', 0.5797820091247559),\n",
       " ('sorpresa', 0.5764471888542175),\n",
       " ('ritrarnelo', 0.5564179420471191),\n",
       " ('rammarico', 0.5516132712364197)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v3.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6a8e8201",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v3.save(os.path.join('../trained_models/Word2Vec40', '40w2v3.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7ad1fa",
   "metadata": {},
   "source": [
    "### Zeitraum 4: 1826-1850"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dfc8abc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text4 = ''\n",
    "\n",
    "for i in df4.lemmatized_text:\n",
    "    text4 += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d304d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 27.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences4 = tokenize_text(text4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0186858c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v4 = Word2Vec(sentences=sentences4,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6985b1e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('panico', 0.5334613919258118),\n",
       " ('bentosto', 0.5279020667076111),\n",
       " ('inspirare', 0.5195204615592957),\n",
       " ('augereau', 0.49806907773017883),\n",
       " ('aristocrazìa', 0.49416160583496094),\n",
       " ('villetard', 0.4853004515171051),\n",
       " ('incusso', 0.4846210479736328),\n",
       " ('cagionare', 0.4836124777793884),\n",
       " ('riurto', 0.4775114953517914),\n",
       " ('scompiglio', 0.47573307156562805)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v4.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "33c0263d",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v4.save(os.path.join('../trained_models/Word2Vec40', '40w2v4.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adbc52f",
   "metadata": {},
   "source": [
    "### Zeitraum 5: 1851-1875"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "14f4f694",
   "metadata": {},
   "outputs": [],
   "source": [
    "text5 = ''\n",
    "\n",
    "for i in df5.lemmatized_text:\n",
    "    text5 += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a37ae9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 30.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences5 = tokenize_text(text5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "14e061e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v5 = Word2Vec(sentences=sentences5,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5dcf457a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sgomento', 0.523679256439209),\n",
       " ('agonia', 0.5085601806640625),\n",
       " ('incutere', 0.5031141042709351),\n",
       " ('ferocia', 0.4934081733226776),\n",
       " ('immaginava', 0.49203574657440186),\n",
       " ('smanioso', 0.48749709129333496),\n",
       " ('ilil', 0.4874187409877777),\n",
       " ('rammarichío', 0.48602941632270813),\n",
       " ('balzelloni', 0.4840412735939026),\n",
       " ('orrore', 0.4827539324760437)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v5.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "890b9950",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v5.save(os.path.join('../trained_models/Word2Vec40', '40w2v5.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8264d8",
   "metadata": {},
   "source": [
    "### Zeitraum 6: 1876-1900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3602dbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text6 = ''\n",
    "\n",
    "for i in df6.lemmatized_text:\n",
    "    text6 += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e68bdf54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 30.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences6 = tokenize_text(text6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "396efd17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v6 = Word2Vec(sentences=sentences6,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ee88f9b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spavento', 0.4669657349586487),\n",
       " ('superstizioso', 0.46506619453430176),\n",
       " ('calamità', 0.4564853012561798),\n",
       " ('forsennato', 0.44041991233825684),\n",
       " ('imputato', 0.43729904294013977),\n",
       " ('carneficina', 0.43668514490127563),\n",
       " ('territio', 0.4300159513950348),\n",
       " ('atterrì', 0.42792680859565735),\n",
       " ('spaventoso', 0.42791056632995605),\n",
       " ('consideravasi', 0.4210168421268463)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v6.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2a67be2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v6.save(os.path.join('../trained_models/Word2Vec40', '40w2v6.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd33346",
   "metadata": {},
   "source": [
    "### Zeitraum 7: 1901-1925"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6c7fc2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text7 = ''\n",
    "\n",
    "for i in df7.lemmatized_text:\n",
    "    text7 += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a61dff94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 28.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences7 = tokenize_text(text7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "274ece89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v7 = Word2Vec(sentences=sentences7,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f97859ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sudar', 0.46295544505119324),\n",
       " ('gelare', 0.45987361669540405),\n",
       " ('sfuggito', 0.454312801361084),\n",
       " ('orrore', 0.4411762058734894),\n",
       " ('accesso', 0.43962740898132324),\n",
       " ('efferato', 0.43903422355651855),\n",
       " ('inopinatamente', 0.4357953667640686),\n",
       " ('stremare', 0.4342036843299866),\n",
       " ('approssimarsi', 0.4321115016937256),\n",
       " ('giovanezza', 0.4310533404350281)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v7.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f3cec0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v7.save(os.path.join('../trained_models/Word2Vec40', '40w2v7.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54934b98",
   "metadata": {},
   "source": [
    "### Zeitraum 8: 1926-1950"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9f32ad8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text8 = ''\n",
    "\n",
    "for i in df8.lemmatized_text:\n",
    "    text8 += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "56c2283a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 26.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences8 = tokenize_text(text8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "20ed4b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v8 = Word2Vec(sentences=sentences8,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7a676dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rabbico', 0.5343318581581116),\n",
       " ('virus', 0.523741602897644),\n",
       " ('innestato', 0.498747855424881),\n",
       " ('agghiacciò', 0.4925477206707001),\n",
       " ('impietrire', 0.4903981387615204),\n",
       " ('canino', 0.4815654158592224),\n",
       " ('pasticcetti', 0.4803818464279175),\n",
       " ('frammettendosi', 0.4795314371585846),\n",
       " ('fours', 0.4747002422809601),\n",
       " ('paralizzare', 0.47211429476737976)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v8.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c618a253",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v8.save(os.path.join('../trained_models/Word2Vec40', '40w2v8.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffecf4f1",
   "metadata": {},
   "source": [
    "### Zeitraum 9: 1951-1975"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "afe767d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text9 = ''\n",
    "\n",
    "for i in df9.lemmatized_text:\n",
    "    text9 += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0e4c1914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 23.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences9 = tokenize_text(text9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e840054a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v9 = Word2Vec(sentences=sentences9,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dad6d0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('malefico', 0.5923131108283997),\n",
       " ('insano', 0.5851815938949585),\n",
       " ('guarentisce', 0.5683953762054443),\n",
       " ('assopita', 0.5673373937606812),\n",
       " ('involare', 0.5580342411994934),\n",
       " ('erastus', 0.5559908747673035),\n",
       " ('favilla', 0.5555555820465088),\n",
       " ('piccolissimo', 0.5522016882896423),\n",
       " ('orrore', 0.5487774610519409),\n",
       " ('spasmodicamente', 0.5479488968849182)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v9.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1f840943",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v9.save(os.path.join('../trained_models/Word2Vec40', '40w2v9.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7eb5cd",
   "metadata": {},
   "source": [
    "### Zeitraum 10: 1976-2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b8d34fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text10 = ''\n",
    "\n",
    "for i in df10.lemmatized_text:\n",
    "    text10+= i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ed3d4cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 26.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences10 = tokenize_text(text10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "35c08bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v10 = Word2Vec(sentences=sentences10,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "60227ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('staliniano', 0.5585861802101135),\n",
       " ('pol', 0.555791437625885),\n",
       " ('bombarolo', 0.5481665730476379),\n",
       " ('autobomba', 0.5478269457817078),\n",
       " ('deportazione', 0.5416848063468933),\n",
       " ('mietere', 0.5411224365234375),\n",
       " ('terrorismo', 0.5408968329429626),\n",
       " ('suicida', 0.5405609607696533),\n",
       " ('maoista', 0.5402685403823853),\n",
       " ('fratricida', 0.5391478538513184)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v10.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e3c2b7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v10.save(os.path.join('../trained_models/Word2Vec40', '40w2v10.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54297223",
   "metadata": {},
   "source": [
    "### Zeitraum 11: 2001-2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2238429e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text11 = ''\n",
    "\n",
    "for i in df11.lemmatized_text:\n",
    "    text11+= i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c480ef84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences11 = tokenize_text(text11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b2b457e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v11 = Word2Vec(sentences=sentences11,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f0a144e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('barbarie', 0.5392811894416809),\n",
       " ('oppressione', 0.5373106002807617),\n",
       " ('fredda', 0.5351439118385315),\n",
       " ('feroce', 0.534885585308075),\n",
       " ('insinuare', 0.5345460176467896),\n",
       " ('tiranno', 0.5345378518104553),\n",
       " ('fondamentalista', 0.5338853597640991),\n",
       " ('fanatismo', 0.5332879424095154),\n",
       " ('irrazionale', 0.5317484736442566),\n",
       " ('irriducibile', 0.52961266040802)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v11.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4e6a41fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v11.save(os.path.join('../trained_models/Word2Vec40', '40w2v11.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb8c247",
   "metadata": {},
   "source": [
    "### Zeitraum 12: 2011-2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2616fbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text12 = ''\n",
    "\n",
    "for i in df12.lemmatized_text:\n",
    "    text12+= i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9bb3ee56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 19.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences12 = tokenize_text(text12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6e729f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v12 = Word2Vec(sentences=sentences12,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a5df2993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ripiombare', 0.6037869453430176),\n",
       " ('seminare', 0.5989764332771301),\n",
       " ('lessico', 0.5811809301376343),\n",
       " ('incutere', 0.5759825706481934),\n",
       " ('cherry', 0.5750294923782349),\n",
       " ('smileys', 0.5644280910491943),\n",
       " ('plum', 0.5637722611427307),\n",
       " ('trapasso', 0.563490092754364),\n",
       " ('desolazione', 0.5593907833099365),\n",
       " ('cieco', 0.557325005531311)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v12.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4b2fc251",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v12.save(os.path.join('../trained_models/Word2Vec40', '40w2v12.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b0d1a1",
   "metadata": {},
   "source": [
    "### Zeitraum 13: 2017-2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "84be08f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text13 = ''\n",
    "\n",
    "for i in df13.lemmatized_text:\n",
    "    text13+= i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fbb3aec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 18.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences13 = tokenize_text(text13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7cb27594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v13 = Word2Vec(sentences=sentences13,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9b5f7cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('incutere', 0.6380201578140259),\n",
       " ('orrore', 0.6357980966567993),\n",
       " ('disorientamento', 0.6223702430725098),\n",
       " ('sadismo', 0.6092866659164429),\n",
       " ('impotenza', 0.6058338284492493),\n",
       " ('lovecraft', 0.6026023030281067),\n",
       " ('oppressione', 0.6009206175804138),\n",
       " ('giacobino', 0.5950257182121277),\n",
       " ('desolazione', 0.59151291847229),\n",
       " ('jihad', 0.5880140662193298)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v13.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "80953244",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v13.save(os.path.join('../trained_models/Word2Vec40', '40w2v13.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02105e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
