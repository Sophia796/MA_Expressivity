{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ba672df",
   "metadata": {},
   "source": [
    "# Trainingspipeline 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bb0ffc",
   "metadata": {},
   "source": [
    "- ohne Bigramme\n",
    "- vector_size: 300\n",
    "- window: 10\n",
    "- seed: 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08e5260c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import nltk\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import scipy\n",
    "import spacy\n",
    "\n",
    "#from gensim.models.phrases import Phraser, Phrases\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import Word2Vec\n",
    "from joblib import Parallel, delayed  \n",
    "from nltk.corpus import stopwords\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09922b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stopwords.words('italian')\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/italian.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46f3e2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Korpus/Korpus/corpus_final.csv', sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d8fa580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>source</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>period</th>\n",
       "      <th>text_type</th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "      <th>lemmatized_text</th>\n",
       "      <th>cleaned_tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Poesia.IV.4.Testo.txt</td>\n",
       "      <td>MIDIA</td>\n",
       "      <td>Faustina Maratti Zappi</td>\n",
       "      <td>Poesie</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1700-1750</td>\n",
       "      <td>poesia</td>\n",
       "      <td>IV. 4. Rime degli Arcadi: Aglauro Cidonia (Fau...</td>\n",
       "      <td>3184.0</td>\n",
       "      <td>iv . 4 . rima del arcadi : aglauro cidonia ( f...</td>\n",
       "      <td>[['iv'], [], ['rima', 'arcadi', 'aglauro', 'ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Espositivi.IV.4.Testo.txt</td>\n",
       "      <td>MIDIA</td>\n",
       "      <td>Ludovico Antonio Muratori</td>\n",
       "      <td>Antichità italiane</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1700-1750</td>\n",
       "      <td>espositivo</td>\n",
       "      <td>﻿IV. 4. Ludovico Antonio Muratori, Antichità i...</td>\n",
       "      <td>8990.0</td>\n",
       "      <td>﻿iv . 4 . Ludovico Antonio muratori , antichit...</td>\n",
       "      <td>[['iv'], [], ['ludovico', 'antonio', 'muratori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Personali.IV.5.Testo.txt</td>\n",
       "      <td>MIDIA</td>\n",
       "      <td>Lorenzo Magalotti</td>\n",
       "      <td>Lettere odorose (1693-1705)</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1700-1750</td>\n",
       "      <td>personale</td>\n",
       "      <td>IV. 5. Lorenzo Magalotti, Lettere odorose (169...</td>\n",
       "      <td>8374.0</td>\n",
       "      <td>iv . 5 . Lorenzo magalotti , lettere odoroso (...</td>\n",
       "      <td>[['iv'], [], ['lorenzo', 'magalotti', 'lettere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Personali.IV.15.Testo.txt</td>\n",
       "      <td>MIDIA</td>\n",
       "      <td>Pietro Giannone</td>\n",
       "      <td>Vita scritta da lui medesimo</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1700-1750</td>\n",
       "      <td>personale</td>\n",
       "      <td>[Proemio]\\nPrendo a scrivere la mia vita e qua...</td>\n",
       "      <td>10118.0</td>\n",
       "      <td>[ proemio ] \\n prendere a scrivere il mio vita...</td>\n",
       "      <td>[['proemio', 'prendere', 'scrivere', 'vita', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Personali.IV.4.Testo.txt</td>\n",
       "      <td>MIDIA</td>\n",
       "      <td>Vincenzo da Filicaia</td>\n",
       "      <td>Lettere inedite a Lorenzo Magalotti</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1700-1750</td>\n",
       "      <td>personale</td>\n",
       "      <td>IV. 4. Vincenzo da Filicaia, Lettere inedite a...</td>\n",
       "      <td>10073.0</td>\n",
       "      <td>iv . 4 . Vincenzo da filicaia , lettere inedit...</td>\n",
       "      <td>[['iv'], [], ['vincenzo', 'filicaia', 'lettere...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         doc source                      author  \\\n",
       "0      Poesia.IV.4.Testo.txt  MIDIA      Faustina Maratti Zappi   \n",
       "1  Espositivi.IV.4.Testo.txt  MIDIA  Ludovico Antonio Muratori    \n",
       "2   Personali.IV.5.Testo.txt  MIDIA           Lorenzo Magalotti   \n",
       "3  Personali.IV.15.Testo.txt  MIDIA             Pietro Giannone   \n",
       "4   Personali.IV.4.Testo.txt  MIDIA        Vincenzo da Filicaia   \n",
       "\n",
       "                                 title    year     period   text_type  \\\n",
       "0                               Poesie  1700.0  1700-1750      poesia   \n",
       "1                   Antichità italiane  1700.0  1700-1750  espositivo   \n",
       "2          Lettere odorose (1693-1705)  1700.0  1700-1750   personale   \n",
       "3         Vita scritta da lui medesimo  1700.0  1700-1750   personale   \n",
       "4  Lettere inedite a Lorenzo Magalotti  1700.0  1700-1750   personale   \n",
       "\n",
       "                                                text    words  \\\n",
       "0  IV. 4. Rime degli Arcadi: Aglauro Cidonia (Fau...   3184.0   \n",
       "1  ﻿IV. 4. Ludovico Antonio Muratori, Antichità i...   8990.0   \n",
       "2  IV. 5. Lorenzo Magalotti, Lettere odorose (169...   8374.0   \n",
       "3  [Proemio]\\nPrendo a scrivere la mia vita e qua...  10118.0   \n",
       "4  IV. 4. Vincenzo da Filicaia, Lettere inedite a...  10073.0   \n",
       "\n",
       "                                     lemmatized_text  \\\n",
       "0  iv . 4 . rima del arcadi : aglauro cidonia ( f...   \n",
       "1  ﻿iv . 4 . Ludovico Antonio muratori , antichit...   \n",
       "2  iv . 5 . Lorenzo magalotti , lettere odoroso (...   \n",
       "3  [ proemio ] \\n prendere a scrivere il mio vita...   \n",
       "4  iv . 4 . Vincenzo da filicaia , lettere inedit...   \n",
       "\n",
       "                              cleaned_tokenized_text  \n",
       "0  [['iv'], [], ['rima', 'arcadi', 'aglauro', 'ci...  \n",
       "1  [['iv'], [], ['ludovico', 'antonio', 'muratori...  \n",
       "2  [['iv'], [], ['lorenzo', 'magalotti', 'lettere...  \n",
       "3  [['proemio', 'prendere', 'scrivere', 'vita', '...  \n",
       "4  [['iv'], [], ['vincenzo', 'filicaia', 'lettere...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d8d584b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(710840, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f02b06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.text = df.text.fillna('')\n",
    "df.lemmatized_text = df.lemmatized_text.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fea6e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einzeldataframes für die Zeiträume\n",
    "\n",
    "df_periods = dict(tuple(df.groupby(by='period')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea8a1150",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_periods['1700-1750']\n",
    "df2 = df_periods['1751-1800']\n",
    "df3 = df_periods['1801-1825']\n",
    "df4 = df_periods['1826-1850']\n",
    "df5 = df_periods['1851-1875']\n",
    "df6 = df_periods['1876-1900']\n",
    "df7 = df_periods['1901-1925']\n",
    "df8 = df_periods['1926-1950']\n",
    "df9 = df_periods['1951-1975']\n",
    "df10 = df_periods['1976-2000']\n",
    "df11 = df_periods['2001-2010']\n",
    "df12 = df_periods['2011-2016']\n",
    "df13 = df_periods['2017-2021']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "524c665b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>source</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>period</th>\n",
       "      <th>text_type</th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "      <th>lemmatized_text</th>\n",
       "      <th>cleaned_tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94810</th>\n",
       "      <td>LISRodari3.txt</td>\n",
       "      <td>LIS</td>\n",
       "      <td>Gianno Rodari</td>\n",
       "      <td>La questione dei fumetti</td>\n",
       "      <td>1951.0</td>\n",
       "      <td>1951-1975</td>\n",
       "      <td>stampa</td>\n",
       "      <td>Caro Direttore , ho letto nell ' ultimo numero...</td>\n",
       "      <td>1510.0</td>\n",
       "      <td>caro direttore , avere leggere nell ' ultimo n...</td>\n",
       "      <td>[['caro', 'direttore', 'avere', 'leggere', 'ul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94811</th>\n",
       "      <td>LISJotti1.txt</td>\n",
       "      <td>LIS</td>\n",
       "      <td>Nilde Jotti</td>\n",
       "      <td>La questione dei fumetti</td>\n",
       "      <td>1951.0</td>\n",
       "      <td>1951-1975</td>\n",
       "      <td>stampa</td>\n",
       "      <td>Il dibattito sulla stampa a fumetti per i raga...</td>\n",
       "      <td>2785.0</td>\n",
       "      <td>il dibattito sulla stampa a fumetto per il rag...</td>\n",
       "      <td>[['dibattito', 'stampa', 'fumetto', 'ragazzo',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94812</th>\n",
       "      <td>LLAlbertelli1.txt</td>\n",
       "      <td>Liber Liber</td>\n",
       "      <td>Pilo Albertelli</td>\n",
       "      <td>Rousseau</td>\n",
       "      <td>1951.0</td>\n",
       "      <td>1951-1975</td>\n",
       "      <td>prosa letteraria</td>\n",
       "      <td>﻿Pilo Albertelli\\nRousseau\\n\\n  Nacque il 28 g...</td>\n",
       "      <td>4894.0</td>\n",
       "      <td>﻿pilo albertelli \\n rousseau \\n\\n   nascere il...</td>\n",
       "      <td>[['pilo', 'albertelli', 'rousseau', 'nascere',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94813</th>\n",
       "      <td>LISManacorda1.txt</td>\n",
       "      <td>LIS</td>\n",
       "      <td>Gastone Manacorda</td>\n",
       "      <td>Il Partito e la sua funzione di guida nel camp...</td>\n",
       "      <td>1951.0</td>\n",
       "      <td>1951-1975</td>\n",
       "      <td>stampa</td>\n",
       "      <td>Al partito , nel suo rigoglioso sviluppo , seg...</td>\n",
       "      <td>3460.0</td>\n",
       "      <td>al partito , nel suo rigoglioso sviluppo , seg...</td>\n",
       "      <td>[['partito', 'rigoglioso', 'sviluppo', 'seguit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94814</th>\n",
       "      <td>LISBianchi1.txt</td>\n",
       "      <td>LIS</td>\n",
       "      <td>Ranuccio Bianchi Bandinelli</td>\n",
       "      <td>Il nostro lavoro nella scuola</td>\n",
       "      <td>1951.0</td>\n",
       "      <td>1951-1975</td>\n",
       "      <td>stampa</td>\n",
       "      <td>Come in tutti i congressi , anche nel VII Cong...</td>\n",
       "      <td>2898.0</td>\n",
       "      <td>come in tutto il congresso , anche nel vii con...</td>\n",
       "      <td>[['congresso', 'vii', 'congresso', 'p'], ['tes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     doc       source                       author  \\\n",
       "94810     LISRodari3.txt          LIS                Gianno Rodari   \n",
       "94811      LISJotti1.txt          LIS                  Nilde Jotti   \n",
       "94812  LLAlbertelli1.txt  Liber Liber              Pilo Albertelli   \n",
       "94813  LISManacorda1.txt          LIS            Gastone Manacorda   \n",
       "94814    LISBianchi1.txt          LIS  Ranuccio Bianchi Bandinelli   \n",
       "\n",
       "                                                   title    year     period  \\\n",
       "94810                           La questione dei fumetti  1951.0  1951-1975   \n",
       "94811                           La questione dei fumetti  1951.0  1951-1975   \n",
       "94812                                           Rousseau  1951.0  1951-1975   \n",
       "94813  Il Partito e la sua funzione di guida nel camp...  1951.0  1951-1975   \n",
       "94814                     Il nostro lavoro nella scuola   1951.0  1951-1975   \n",
       "\n",
       "              text_type                                               text  \\\n",
       "94810            stampa  Caro Direttore , ho letto nell ' ultimo numero...   \n",
       "94811            stampa  Il dibattito sulla stampa a fumetti per i raga...   \n",
       "94812  prosa letteraria  ﻿Pilo Albertelli\\nRousseau\\n\\n  Nacque il 28 g...   \n",
       "94813            stampa  Al partito , nel suo rigoglioso sviluppo , seg...   \n",
       "94814            stampa  Come in tutti i congressi , anche nel VII Cong...   \n",
       "\n",
       "        words                                    lemmatized_text  \\\n",
       "94810  1510.0  caro direttore , avere leggere nell ' ultimo n...   \n",
       "94811  2785.0  il dibattito sulla stampa a fumetto per il rag...   \n",
       "94812  4894.0  ﻿pilo albertelli \\n rousseau \\n\\n   nascere il...   \n",
       "94813  3460.0  al partito , nel suo rigoglioso sviluppo , seg...   \n",
       "94814  2898.0  come in tutto il congresso , anche nel vii con...   \n",
       "\n",
       "                                  cleaned_tokenized_text  \n",
       "94810  [['caro', 'direttore', 'avere', 'leggere', 'ul...  \n",
       "94811  [['dibattito', 'stampa', 'fumetto', 'ragazzo',...  \n",
       "94812  [['pilo', 'albertelli', 'rousseau', 'nascere',...  \n",
       "94813  [['partito', 'rigoglioso', 'sviluppo', 'seguit...  \n",
       "94814  [['congresso', 'vii', 'congresso', 'p'], ['tes...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df9.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8298b52a",
   "metadata": {},
   "source": [
    "## Training von Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44b8d2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hilfsfunktionen zur Vorbereitung auf das Training\n",
    "# Bereinigung und Tokenisierung\n",
    "\n",
    "def sentence_to_wordlist(raw:str):\n",
    "    \"\"\"\n",
    "    cleans and tokenizes the sentences\n",
    "    \"\"\"\n",
    "    text = re.sub('[^A-Za-z_àÀèÈìÌòÒùÙáÁéÉíÍóÓúÚ]',' ', raw).split()        # Diakritika ans Italienische anpassen                    \n",
    "    filtered_text = [word for word in text if word not in stopwords]        # Stopwörter löschen\n",
    "    return filtered_text\n",
    "\n",
    "\n",
    "def tokenize_text(raw_text):\n",
    "    \"\"\"\n",
    "    returns a list of lowercase tokenized sentences \n",
    "    \"\"\"\n",
    "    raw_sentences = tokenizer.tokenize(str(raw_text).lower())    \n",
    "    tokenized_sentences = Parallel(n_jobs=-1)(delayed(sentence_to_wordlist)(raw_sentence) for raw_sentence in raw_sentences)\n",
    "    sentences = tokenized_sentences\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "167dbe44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainingsparamter setzen\n",
    "\n",
    "vector_size = 300                  # Dimensionality of the word vectors\n",
    "window = 10                        # The maximum distance between the current and predicted word within a sentence\n",
    "min_count = 2                      # (int, optional) – The model ignores all words with total frequency lower than this\n",
    "workers = 1                        # Use these many worker threads to train the model (faster training with multicore machines)\n",
    "min_alpha = 0.0001                 # Learning rate will linearly drop to min_alpha as training progresses\n",
    "sg = 1                             # Training algorithm: skip-gram if sg=1, otherwise CBOW            \n",
    "seed = 42                          # Reproductivity (42 just because...) --> only if workers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cab9952f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordner anlegen zum Abspeichern von trainierten Modellen\n",
    "\n",
    "if not os.path.exists('../trained_models'):\n",
    "    os.makedirs('../trained_models')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8d041b",
   "metadata": {},
   "source": [
    "### Zeitraum 1: 1700-1750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a28475c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatisierte Texte zu einem String verbinden\n",
    "\n",
    "text1 = ''\n",
    "\n",
    "for i in df1.lemmatized_text:\n",
    "    text1 += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd305b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences1 = tokenize_text(text1)         # Bereinigen, Tokenisieren und in Form bringen (Ziel: Liste von tokenisierten Sätzen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d40ec629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['iv'], [], ['rima', 'arcadi', 'aglauro', 'cidonia', 'faustina', 'maratti', 'zappi', 'aglauro', 'cidonia', 'credea', 'debil', 'navicella', 'rotta', 'onda', 'stancare', 'cammino', 'ritrar', 'porto', 'scorgea', 'vicino', 'ch', 'troppo', 'scorso', 'parte'], ['credea', 'gi', 'calmare', 'ogni', 'procella', 'saziare', 'parte', 'crudel', 'destino', 'ciel', 'pi', 'sereno', 'me', 'divino', 'raggio', 'mostrare', 'propizio', 'stella'], ['barbaro', 'clima', 'vento', 'sorgere', 'sospingere', 'forza', 'scoglio', 'tal', 'naviglio', 'ahi', 'fia', 'onda', 'assorto']]\n"
     ]
    }
   ],
   "source": [
    "print(sentences1[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0547e952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82675"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f3bbf96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Training   \n",
    "\n",
    "w2v1 = Word2Vec(sentences=sentences1,                      \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac18caca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spavento', 0.7818655371665955),\n",
       " ('armi', 0.7175211906433105),\n",
       " ('goti', 0.7045249342918396),\n",
       " ('paura', 0.6868568658828735),\n",
       " ('faceano', 0.6861615777015686),\n",
       " ('spaventare', 0.6838738322257996),\n",
       " ('barbari', 0.6772375702857971),\n",
       " ('costernazione', 0.6576120853424072),\n",
       " ('addossare', 0.6540018320083618),\n",
       " ('pannonia', 0.6525850892066956)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v1.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ddba9921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainiertes Modell speichern\n",
    "\n",
    "w2v1.save(os.path.join('../trained_models/Word2Vec0', 'w2v1.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd3a0bc",
   "metadata": {},
   "source": [
    "### Zeitraum 2: 1751-1800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1f4c26d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = ''\n",
    "\n",
    "for i in df2.lemmatized_text:\n",
    "    text2 += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eaa2b3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences2 = tokenize_text(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c019e034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['vita', 'antonio', 'genovese', 'antonio', 'genovese', 'avo', 'avere', 'ereditare', 'padre', 'dote', 'moglie', 'giustina', 'genovese', 'avere', 'terra', 'tanto', 'onda', 'poco', 'industria', 'avere', 'potere', 'solo', 'vivere', 'comodit', 'molto', 'accrescere', 'patrimonio'], ['poltroneria', 'scem'], ['avere', 'sette', 'figlio', 'tre', 'maschio', 'quattro', 'femine'], ['femine', 'due', 'morire', 'pulcelle', 'due', 'essere', 'maritate'], ['de', 'maschio', 'secondo', 'mor', 'cherico', 'ultimo', 'cambio', 'cielo', 'stabil', 'altrove']]\n"
     ]
    }
   ],
   "source": [
    "print(sentences2[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "23de71b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144740"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ee58cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v2 = Word2Vec(sentences=sentences2,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9f2382df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spavento', 0.7384335994720459),\n",
       " ('ostile', 0.6631743311882019),\n",
       " ('barbari', 0.6546300053596497),\n",
       " ('legione', 0.6460967063903809),\n",
       " ('inspirare', 0.6396669149398804),\n",
       " ('orrore', 0.636448085308075),\n",
       " ('atterrire', 0.6330591440200806),\n",
       " ('strage', 0.6319993138313293),\n",
       " ('usurpatore', 0.6258938312530518),\n",
       " ('crociati', 0.6238396167755127)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v2.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "912ce604",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v2.save(os.path.join('../trained_models/Word2Vec0', 'w2v2.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12799bcb",
   "metadata": {},
   "source": [
    "### Zeitraum 3: 1801-1825"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "31895854",
   "metadata": {},
   "outputs": [],
   "source": [
    "text3 = ''\n",
    "\n",
    "for i in df3.lemmatized_text:\n",
    "    text3 += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b20f1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences3 = tokenize_text(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e2aa35ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['effetti', 'fame', 'disperazione', 'uomo'], ['autore', 'viaggio', 'alto', 'pensilvania', 'nuovo', 'york', 'libro', 'stampare', 'poco', 'anno', 'filadelfia', 'ristampare', 'londra', 'descrivere', 'secondo', 'que', 'tre', 'volume', 'avvenimento', 'essere', 'riescire', 'funesto', 'tanto', 'compagno', 'viaggio', 'raccontare', 'tradurre', 'fedelmente', 'solo', 'perchè', 'opera', 'inglese', 'essere', 'poco', 'noto', 'italia', 'eziandio', 'perchè', 'fatto', 'confermare', 'alcune', 'poco', 'vero', 'nozione', 'tanto', 'secolo', 'esperienza', 'studio', 'avere', 'appena', 'potere', 'dare', 'natura', 'uomo'], ['compiacere', 'desiderio', 'esaminare', 'monte', 'allegheni', 'sig'], ['hermann', 'amicizia', 'abbandonare', 'mai', 'tanto', 'anno', 'viaggio', 'così', 'penoso', 'avviare', 'meco', 'fare', 'giorno', 'provvedendosi', 'battifuoco', 'pietra', 'focaia', 'bisogno', 'onda', 'scoprire', 'albero', 'ape', 'chiamare', 'paese', 'bee', 'tree'], ['ape', 'recare', 'primo', 'volta', 'europeo', 'crescere', 'allontanare', 'frotta', 'abitato']]\n"
     ]
    }
   ],
   "source": [
    "print(sentences3[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "328353f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85065"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2f33cd50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v3 = Word2Vec(sentences=sentences3,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fc887350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('repentino', 0.7741665840148926),\n",
       " ('spavento', 0.7676851153373718),\n",
       " ('eccitare', 0.7564024925231934),\n",
       " ('calma', 0.7475305795669556),\n",
       " ('abbattimento', 0.7370861172676086),\n",
       " ('sorpresa', 0.7312561273574829),\n",
       " ('orrore', 0.730105459690094),\n",
       " ('atterrire', 0.7290980815887451),\n",
       " ('infiammare', 0.7270755767822266),\n",
       " ('calmare', 0.7255777716636658)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v3.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6a8e8201",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v3.save(os.path.join('../trained_models/Word2Vec0', 'w2v3.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7ad1fa",
   "metadata": {},
   "source": [
    "### Zeitraum 4: 1826-1850"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dfc8abc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text4 = ''\n",
    "\n",
    "for i in df4.lemmatized_text:\n",
    "    text4 += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4d304d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences4 = tokenize_text(text4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "38fd5eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['canto', 'cominciar', 'novello', 'canto', 'tenere', 'eliconie', 'cima', 'prego', 'vergine', 'dee', 'concilio', 'santo', 'stile', 'conduciate', 'rima', 'topo', 'rana', 'caso', 'acerbo', 'ira', 'segno', 'insolito', 'carmi', 'prendere', 'dire'], ['cetra', 'avere', 'man', 'carta', 'grembo', 'or', 'data', 'principio', 'fine', 'opra', 'virtù', 'molto', 'tardo', 'etate', 'suoni', 'dive', 'carme', 'fia', 'foglio', 'sacrati', 'scrivere', 'chiaro', 'fama', 'eternamente', 'vivo'], ['terrigeni', 'eroi', 'vasto', 'giganti', 'que', 'topo', 'imitare', 'schiatta', 'audace', 'dolor', 'furor', 'caldo', 'spumante', 'venire', 'campo', 'essere', 'fallace', 'memoria', 'romor', 'ch', 'oggi', 'restare', 'cagion', 'de', 'collera', 'essere'], ['topo', 'de', 'membra', 'molto', 'ben', 'fare', 'venne', 'lago', 'sponda', 'giorno'], ['campato', 'poco', 'innanzi', 'essere', 'gatto', 'ch', 'inseguire', 'avea', 'dintorno', 'stanco', 'faceasi', 'bere', 'quando', 'ranocchio', 'passare', 'vicin', 'porre', 'occhio']]\n"
     ]
    }
   ],
   "source": [
    "print(sentences4[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "305925ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109750"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0186858c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v4 = Word2Vec(sentences=sentences4,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6985b1e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spavento', 0.6297602653503418),\n",
       " ('bentosto', 0.5547863245010376),\n",
       " ('atterrire', 0.5531451106071472),\n",
       " ('cagionare', 0.533476710319519),\n",
       " ('fuga', 0.5299801230430603),\n",
       " ('inspirare', 0.5289738178253174),\n",
       " ('buonaparte', 0.5227904319763184),\n",
       " ('scompiglio', 0.5160790681838989),\n",
       " ('repubblicano', 0.5114613175392151),\n",
       " ('panico', 0.5059127807617188)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v4.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "33c0263d",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v4.save(os.path.join('../trained_models/Word2Vec0', 'w2v4.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adbc52f",
   "metadata": {},
   "source": [
    "### Zeitraum 5: 1851-1875"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "14f4f694",
   "metadata": {},
   "outputs": [],
   "source": [
    "text5 = ''\n",
    "\n",
    "for i in df5.lemmatized_text:\n",
    "    text5 += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4a37ae9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 23.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences5 = tokenize_text(text5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1fa1a790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ch', 'ei', 'volere', 'udir', 'invan', 'pregai', 'ogni', 'adito', 'essere', 'chiudere', 'deriso', 'solo', 'partire', 'sapea', 'oggi', 'gioia', 'rammentare', 'alfine'], ['pentire', 'dicea', 'rivedere', 'condottier', 'de', 'nemico', 'ingrato'], ['bei', 'versovi', 'comprendere', 'voce', 'pubblico', 'riferire', 'opinione', 'assolutamente', 'falso'], ['sicchè', 'avere', 'mai', 'sapere', 'nulla', 'finora', 'fidanzamento'], ['mai', 've', 'assicuro']]\n"
     ]
    }
   ],
   "source": [
    "print(sentences5[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "223a2a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200080"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "14e061e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v5 = Word2Vec(sentences=sentences5,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5dcf457a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sgomento', 0.5896665453910828),\n",
       " ('spavento', 0.5500238537788391),\n",
       " ('incutere', 0.5356026291847229),\n",
       " ('atterrire', 0.525767982006073),\n",
       " ('agonia', 0.5236062407493591),\n",
       " ('raccapriccio', 0.5233415365219116),\n",
       " ('rammarichío', 0.5171985626220703),\n",
       " ('rimorso', 0.5131546258926392),\n",
       " ('fremito', 0.5111005306243896),\n",
       " ('orrore', 0.5102239847183228)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v5.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "890b9950",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v5.save(os.path.join('../trained_models/Word2Vec0', 'w2v5.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8264d8",
   "metadata": {},
   "source": [
    "### Zeitraum 6: 1876-1900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3602dbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text6 = ''\n",
    "\n",
    "for i in df6.lemmatized_text:\n",
    "    text6 += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e68bdf54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 27.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences6 = tokenize_text(text6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "650a82c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['notte', 'intiera', 'intiera', 'battere', 'dente', 'nota', 'cicogna', 'crepare', 'fame', 'scoppiare', 'sete', 'schiattare', 'paura'], ['capitano', 'fare', 'sciogliere', 'rifocillare', 'meglio', 'procedere', 'interrogatorio'], ['sebbene', 'avere', 'contrattare', 'certo', 'modo', 'obbligo', 'morale', 'provvedere', 'sempre'], ['no', 'vecchierella', 'andare', 'nè', 'domani', 'nè', 'mai', 'abbandonare', 'molto', 'molto'], ['già', 'do', 'licenza', 'partire', 'dovere', 'anco', 'costare', 'grande', 'cattivoscarabocchiare', 'muro', 'accanto', 'frasca', 'canonico', 'motto', 'quando', 'cantare', 'credito', 'fare', 'oggi', 'no', 'domani', 'sì', 'patti', 'chiaro', 'amico', 'caro']]\n"
     ]
    }
   ],
   "source": [
    "print(sentences6[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7305ee69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "253332"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "396efd17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v6 = Word2Vec(sentences=sentences6,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ee88f9b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spavento', 0.5120231509208679),\n",
       " ('sgomento', 0.49296483397483826),\n",
       " ('calamità', 0.4630604386329651),\n",
       " ('carneficina', 0.4507082998752594),\n",
       " ('assalire', 0.4444493055343628),\n",
       " ('orrore', 0.4390488266944885),\n",
       " ('superstizioso', 0.4352823793888092),\n",
       " ('atroce', 0.43413981795310974),\n",
       " ('sbigottimento', 0.43274128437042236),\n",
       " ('ildi', 0.43120402097702026)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v6.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2a67be2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v6.save(os.path.join('../trained_models/Word2Vec0', 'w2v6.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd33346",
   "metadata": {},
   "source": [
    "### Zeitraum 7: 1901-1925"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6c7fc2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text7 = ''\n",
    "\n",
    "for i in df7.lemmatized_text:\n",
    "    text7 += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a61dff94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences7 = tokenize_text(text7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f7fe0e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['preghiera', 'porre', 'letto'], ['mattino', 'vegnente', 'tempissimo', 'avere', 'riga', 'caro', 'quando', 'ieri', 'k', 'nigswinter', 'essere', 'rimanere', 'solo', 'te', 'avere', 'volere', 'dire', 'avere', 'potere', 'avere', 'vistare', 'avere', 'solamente', 'poterelampeggiare', 'gioia', 'quando', 'parlare', 'poesia', 'scrivere', 'notte'], ['ecco', 'esclamare', 'speranza', 'ieri'], ['quando', 'vedere', 'com', 'scrivere', 'cinque', 'verso', 'inesprimibile', 'amore', 'dire', 'guardare', 'fiso', 'stessoparte', 'almea'], ['sorseggiare', 'qualche', 'poco', 'poi', 'uscire', 'compiere', 'difficile', 'missione']]\n"
     ]
    }
   ],
   "source": [
    "print(sentences7[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1f5d6033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178123"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "274ece89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v7 = Word2Vec(sentences=sentences7,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f97859ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sgomento', 0.5956056714057922),\n",
       " ('orrore', 0.5933123826980591),\n",
       " ('invincibile', 0.568263590335846),\n",
       " ('raccapriccio', 0.5543478727340698),\n",
       " ('ribrezzo', 0.5444951057434082),\n",
       " ('giovanezza', 0.5438083410263062),\n",
       " ('furore', 0.538895845413208),\n",
       " ('doloroso', 0.5327672958374023),\n",
       " ('gelare', 0.5319389700889587),\n",
       " ('estrema', 0.5288732051849365)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v7.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f3cec0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v7.save(os.path.join('../trained_models/Word2vec0', 'w2v7.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54934b98",
   "metadata": {},
   "source": [
    "### Zeitraum 8: 1926-1950"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9f32ad8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text8 = ''\n",
    "\n",
    "for i in df8.lemmatized_text:\n",
    "    text8 += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "56c2283a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences8 = tokenize_text(text8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7d7067be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['offesa', 'essere', 'principalmente', 'anzi', 'unicamente', 'incolpevole', 'quali', 'essere', 'umano', 'schierare', 'capo', 'gregario', 'sciopero', 'partito', 'volere', 'esso', 'esaltare'], ['così', 'oggi', 'dopo', 'due', 'lungo', 'sciopero', 'breve', 'distanza', 'altro', 'esempio', 'insigne', 'immedicata', 'follia', 'nazione', 'essere', 'socialista', 'volere', 'chiamare', 'giudice', 'moderatore', 'lotta', 'vita', 'nazionale', 'essere', 'avvelenare', 'tormentato'], ['monito', 'essere', 'formidabilmente', 'chiaro'], ['cronaca', 'sciopero', 'levare', 'verso', 'governo', 'essere', 'd', 'gravità', 'minore'], ['governo', 'avere', 'ereditare', 'tradizione', 'dubbiezza', 'quindi', 'debolezza', 'essere', 'certo', 'difficile', 'liberare', 'bisognare', 'pure', 'ogni', 'costo', 'liberare']]\n"
     ]
    }
   ],
   "source": [
    "print(sentences8[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "95d1778e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120296"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "20ed4b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v8 = Word2Vec(sentences=sentences8,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7a676dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spavento', 0.659649670124054),\n",
       " ('rabbico', 0.6314923167228699),\n",
       " ('invasare', 0.6233468651771545),\n",
       " ('virus', 0.610973596572876),\n",
       " ('rabbia', 0.6052799224853516),\n",
       " ('sgomento', 0.6034482717514038),\n",
       " ('stupore', 0.6022142767906189),\n",
       " ('scossa', 0.5934126973152161),\n",
       " ('subitaneo', 0.5883880257606506),\n",
       " ('tortura', 0.5856361389160156)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v8.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c618a253",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v8.save(os.path.join('../trained_models/Word2Vec0', 'w2v8.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffecf4f1",
   "metadata": {},
   "source": [
    "### Zeitraum 9: 1951-1975"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "afe767d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text9 = ''\n",
    "\n",
    "for i in df9.lemmatized_text:\n",
    "    text9 += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0e4c1914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences9 = tokenize_text(text9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e037d858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['caro', 'direttore', 'avere', 'leggere', 'ultimo', 'numero', 'rinascita', 'articolo', 'nilde', 'jotti', 'questione', 'fumetto', 'desiderare', 'esprimere', 'opinione', 'dire', 'subito', 'articolo', 'jotti', 'convincere'], ['esso', 'prendere', 'spunto', 'dibattito', 'corso', 'camera', 'stampa', 'ragazzo', 'giustamente', 'respingere', 'reazionario', 'inefficace', 'legge', 'proporre', 'democristiano', 'soltanto', 'contrario', 'principio', 'costituzionale', 'libertà', 'stampa', 'aut', 'decadenza', 'corruzione', 'delinquenza', 'giovane', 'dilagare', 'fumetto', 'essere', 'fatto', 'collegati', 'effetto', 'causa', 'bensì', 'manifestazione', 'diverso', 'realtà', 'unico'], ['bisognare', 'affrontare', 'risolvere', 'dire', 'giustamente', 'jotti', 'questione', 'orientamento', 'ideale', 'pratico', 'educazione', 'sviluppo', 'intellettuale', 'monile', 'giovane'], ['fare', 'mettere', 'dito', 'piaga', 'essere', 'ordine', 'economico', 'sociale', 'politico'], ['posizione', 'confronto', 'legge', 'fumetto', 'essere', 'giusto', 'fondare', 'realtà', 'pratica', 'ragionamento', 'accademico']]\n"
     ]
    }
   ],
   "source": [
    "print(sentences9[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f334150e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82070"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e840054a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v9 = Word2Vec(sentences=sentences9,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "dad6d0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('maledizione', 0.9087971448898315),\n",
       " ('orrore', 0.9022539854049683),\n",
       " ('feroce', 0.8848339319229126),\n",
       " ('impotente', 0.8827385306358337),\n",
       " ('disperazione', 0.8815580606460571),\n",
       " ('tremendo', 0.8806217908859253),\n",
       " ('sconvolgere', 0.8744029998779297),\n",
       " ('mortale', 0.8607144951820374),\n",
       " ('orrendo', 0.8597286939620972),\n",
       " ('silvana', 0.8518133759498596)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v9.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1f840943",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v9.save(os.path.join('../trained_models/Word2vec0', 'w2v9.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7eb5cd",
   "metadata": {},
   "source": [
    "### Zeitraum 10: 1976-2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b8d34fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text10 = ''\n",
    "\n",
    "for i in df10.lemmatized_text:\n",
    "    text10+= i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ed3d4cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences10 = tokenize_text(text10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b163c094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['essere', 'dire', 'andare', 'piano'], ['problema', 'affrontare', 'volta'], ['visti', 'così', 'blocco', 'spaventare'], ['ex', 'dc', 'riaffacciare', 'viminale', 'avere', 'governare', 'anno'], ['essere', 'pure', 'napoletano', 'usare', 'trebbiano']]\n"
     ]
    }
   ],
   "source": [
    "print(sentences10[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8fe32b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221424"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "35c08bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v10 = Word2Vec(sentences=sentences10,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "60227ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pol', 0.5746635794639587),\n",
       " ('staliniano', 0.5730768442153931),\n",
       " ('incubo', 0.5587969422340393),\n",
       " ('terrorista', 0.5567649602890015),\n",
       " ('stalin', 0.5565236210823059),\n",
       " ('khmer', 0.5512040853500366),\n",
       " ('deportazione', 0.5476601719856262),\n",
       " ('sanguinario', 0.546563446521759),\n",
       " ('mietere', 0.5461190342903137),\n",
       " ('pot', 0.5460801720619202)]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v10.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e3c2b7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v10.save(os.path.join('../trained_models/Word2Vec0', 'w2v10.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54297223",
   "metadata": {},
   "source": [
    "### Zeitraum 11: 2001-2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2238429e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text11 = ''\n",
    "\n",
    "for i in df11.lemmatized_text:\n",
    "    text11+= i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c480ef84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 21.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences11 = tokenize_text(text11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3bb1c3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['durante', 'perquisizione', 'casa', 'due', 'malvivente', 'essere', 'stare', 'rinvenire', 'pistola', 'beretta', 'calibro', 'sw', 'regolarmente', 'denunciare', 'danilo', 'fazio', 'guardia', 'particolare', 'giurata', 'servizio', 'presso', 'agenzia', 'lodi', 'tfr', 'genitore', 'aiutare', 'figlio', 'invece', 'così', 'avere', 'aiutare', 'stato', 'centrale', 'fiat', 'avere', 'annunciare', 'arrivo', 'nuovo', 'limited', 'edition', 'denominata', 'blackjack', 'estate', 'italiano', 'cantare', 'insieme', 'bennato'], ['laureare', 'filosofia'], ['battista', 'bertoglio', 'nato', 'crevacuore', 'oggi', 'biella', 'dicembre', 'decedere', 'crevacuore', 'maggio', 'ristoratore', 'pioniere', 'socialismo'], ['membromundial', 'oggi', 'avere', 'esordire', 'commento', 'corrirere', 'sera'], ['dire']]\n"
     ]
    }
   ],
   "source": [
    "print(sentences11[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3972f69c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110514"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b2b457e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v11 = Word2Vec(sentences=sentences11,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f0a144e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('terrorismo', 0.5717010498046875),\n",
       " ('oppressione', 0.5685752630233765),\n",
       " ('barbarie', 0.5531708598136902),\n",
       " ('insinuare', 0.5527194738388062),\n",
       " ('orrore', 0.5459117293357849),\n",
       " ('malvagità', 0.5454167723655701),\n",
       " ('ceceno', 0.5444887280464172),\n",
       " ('menzogna', 0.5441189408302307),\n",
       " ('carestia', 0.5426889061927795),\n",
       " ('fondamentalista', 0.5409315824508667)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v11.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4e6a41fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v11.save(os.path.join('../trained_models/Word2Vec0', 'w2v11.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb8c247",
   "metadata": {},
   "source": [
    "### Zeitraum 12: 2011-2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2616fbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text12 = ''\n",
    "\n",
    "for i in df12.lemmatized_text:\n",
    "    text12+= i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9bb3ee56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 20.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences12 = tokenize_text(text12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1cbb081d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['terzo', 'coppia', 'schiacciatore', 'essere', 'lanza', 'kovar', 'bei', 'tempo', 'quando', 'scuola', 'insegnare', 'economia', 'domestico', 'comportamentale', 'avere', 'fare', 'ottimo', 'partita', 'volta', 'essere', 'stare', 'po', 'sfortunato', 'avere', 'quasi', 'sempre', 'creare', 'tanto', 'occasione', 'cicloamatore', 'com', 'volere', 'essere', 'piccolo', 'social', 'network', 'punto', 'incontro', 'amante', 'bicicletta', 'giorno', 'potere', 'dichiarare', 'molto', 'globale', 'totale', 'valere', 'dire', 'intelligente', 'lucido', 'ambizioso', 'solidale'], ['essere', 'molto', 'semplice', 'bastare', 'cliccare', 'cromimi', 'poi', 'stare', 'scheda', 'profilo', 'infine', 'nome'], ['apparire', 'così', 'ilil', 'presidente', 'pietracupa', 'avere', 'preferire', 'spostare', 'altro', 'data', 'convocazione', 'consiglio', 'gay', 'potere', 'entrare', 'forza', 'armato', 'usa', 'senza', 'obbligo', 'tenere', 'nascondere', 'omosessualità', 'entrambi', 'essere', 'erbivoro', 'avere', 'corno', 'elaborare', 'abbellimento', 'testa', 'condizione', 'due', 'anziano', 'risultare', 'grave', 'oggi', 'minicar', 'venire', 'togliere', 'acqua', 'porto', 'dopo', 'ieri', 'essere', 'stare', 'mettere', 'sicurezza', 'uomo', 'capitaneria', 'porto'], ['indirizzo', 'generale', 'attività', 'scuola', 'collegamento', 'internet', 'durare', 'poco', 'procura', 'responsabile', 'imprenditore', 'italiani', 'forlì', 'svoltare', 'divano', 'pulito', 'potere', 'essere', 'umano', 'risolvere', 'giorno', 'casino', 'simile', 'cercare', 'corto', 'circuito', 'emotivo', 'visione', 'bambino', 'violare', 'fare', 'scattare', 'ogni', 'padre', 'ogni', 'madre', 'terrore', 'violazione', 'proprio', 'bambino', 'allora', 'spegnere', 'televisione', 'televisione', 'possibile', 'apertoche', 'avere', 'disposizione', 'conoscere', 'meglio', 'molto', 'fondo', 'interno', 'forum', 'dopo', 'topic', 'presentazione'], ['poi', 'essere', 'sempre', 'occasione', 'fare', 'risata', 'molto']]\n"
     ]
    }
   ],
   "source": [
    "print(sentences12[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8b53f37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71000"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6e729f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v12 = Word2Vec(sentences=sentences12,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a5df2993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ripiombare', 0.6244481801986694),\n",
       " ('raccapriccio', 0.5971750617027283),\n",
       " ('incutere', 0.5971723794937134),\n",
       " ('desolazione', 0.5969581604003906),\n",
       " ('paura', 0.5870728492736816),\n",
       " ('angoscia', 0.5868802070617676),\n",
       " ('seminare', 0.5838741064071655),\n",
       " ('poliziesco', 0.5799481272697449),\n",
       " ('miseria', 0.5793553590774536),\n",
       " ('ferocia', 0.5748189687728882)]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v12.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4b2fc251",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v12.save(os.path.join('../trained_models/Word2Vec0', 'w2v12.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b0d1a1",
   "metadata": {},
   "source": [
    "### Zeitraum 13: 2017-2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "84be08f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text13 = ''\n",
    "\n",
    "for i in df13.lemmatized_text:\n",
    "    text13+= i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fbb3aec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 18.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences13 = tokenize_text(text13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "83123aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['candidato', 'dovere', 'essere', 'centrosinistra', 'indeciso', 'abbandonare', 'chávez', 'votare', 'qualcuno', 'destra', 'senso', 'egli', 'essere', 'sicuro', 'fanciulla', 'essere', 'altezza', 'cotanto', 'cliente', 'avere', 'personalmente', 'sperimentare', 'piano', 'orizzontale', 'direzione', 'essere', 'articolato', 'servizio', 'divisione', 'due', 'ufficio', 'seguito', 'elencare', 'svolgere', 'attività', 'principale', 'evidenziare', 'avere', 'fare', 'eco', 'cassidy', 'nasa', 'sottolineare', 'stare', 'applicare', 'stesso', 'precauzione', 'prendere', 'resto', 'mondo', 'distanziamento', 'sociale', 'post', 'profilo', 'facebook', 'poi', 'rimuovere', 'avere', 'chiedere', 'potere', 'avere', 'bambino', 'parotite', 'residente', 'marche', 'sottoporre', 'meglio', 'precisato', 'esperimento', 'essere', 'molto', 'medico'], ['nuovo', 'presidente', 'ordine', 'medici', 'indicazione', 'ats', 'insubria', 'controllare', 'ospite', 'dovere', 'avere', 'febbre', 'particolare', 'resistenza', 'antibiotico', 'spiegare', 'presidente', 'essere', 'screening', 'atto', 'momento', 'risultare', 'situazione', 'genere', 'estensione', 'deducibilita', 'costo', 'lavoro', 'imponibile', 'irap', 'limite', 'lavoratore', 'stagionale', 'antonio', 'fadda', 'essere', 'infermiere', 'austis', 'piccolo', 'centro', 'nuorese', 'essere', 'amico', 'raccontare', 'azzollini', 'scomparsa', 'poco', 'giorno', 'fa', 'avere', 'colpire', 'molto', 'corruzione', 'tassa', 'nascondere', 'euro', 'anno', 'momento', 'voto', 'iren', 'essere', 'uscire', 'aula', 'diversi', 'consigliere', 'minoranza', 'pdl', 'progetto', 'reggio', 'udc', 'risultato', 'fare', 'saltare', 'definitivamente', 'lavoro', 'comitato', 'europeo', 'regione', 'essere', 'organo', 'ue', 'sedere', 'rappresentante', 'ente', 'locale', 'stato', 'membro', 'regione', 'provincia', 'comune', 'così', 'maresciallo', 'grande', 'vincenzo', 'carlo', 'gennaro', 'residenza', 'massimiliano', 'carlotta', 'potere', 'beneficiare', 'fondo', 'previsto', 'luogo', 'cuore', 'legge', 'assestamento', 'provincia', 'avere', 'stanziare', 'fondo', 'programma', 'evento', 'animare', 'essere', 'zona', 'ponte', 'tresa', 'area', 'festa', 'lavena', 'prendere', 'via', 'fine', 'settimana', 'volo', 'operare', 'aeronautica', 'militare', 'italiano', 'biocontenimento', 'coordinare', 'ministero', 'difesa', 'protezione', 'civile', 'essere', 'affiancare', 'luftwaffe', 'cosi', 'sporcare', 'cuore', 'figlio', 'senza', 'consenso', 'genitore', 'dbrs', 'morningstar', 'confermare', 'rating', 'asso', 'brasiliano', 'psg', 'essere', 'amico', 'renan', 'pizzo', 'universale', 'italobrasiliano', 'club', 'gialloverde', 'r'], ['fotocopia', 'documento', 'riconoscimento', 'indirizzare', 'comune', 'varese', 'ufficio', 'ricerca', 'selezione', 'personale', 'via', 'sacco', 'n', 'varese', 'oppure', 'trasmettere', 'via', 'telematico', 'sito', 'certificato', 'pec', 'altre', 'essere', 'stare', 'costringere', 'fare', 'test', 'gravidanza', 'proseguire', 'amnesty', 'international', 'settembre', 'fare', 'riunione', 'plenario', 'poi', 'fare', 'altre', 'zona', 'commerciante', 'dovere', 'eleggere', 'rappresentante', 'consulta', 'presidente', 'essere', 'rimanere', 'ferire', 'nahce', 'meno', 'gravemente', 'enne', 'riminese', 'guida', 'furgone', 'trasportare', 'ospedale', 'rimini', 'invece', 'vito', 'casula', 'essere', 'rimanere', 'entusiasta', 'avere', 'consegnare', 'ieri', 'mattina', 'presidente', 'zingaretti', 'spiegare', 'fredda', 'latino', 'proposta', 'unitario', 'leu', 'individuazione', 'figura', 'avere', 'dovere', 'ricoprire', 'ruolo', 'assessore']]\n"
     ]
    }
   ],
   "source": [
    "print(sentences13[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6c7bf223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60249"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7cb27594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v13 = Word2Vec(sentences=sentences13,                   \n",
    "                vector_size=vector_size,          \n",
    "                window=window,                \n",
    "                min_count=min_count,              \n",
    "                workers=workers, \n",
    "                min_alpha=min_alpha,         \n",
    "                sg=sg,                     \n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9b5f7cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('incutere', 0.6577876210212708),\n",
       " ('orrore', 0.6476606726646423),\n",
       " ('crudeltà', 0.6427705883979797),\n",
       " ('mostruoso', 0.6361666917800903),\n",
       " ('seminare', 0.6358979940414429),\n",
       " ('disorientamento', 0.6341649889945984),\n",
       " ('esorcizzare', 0.6223713159561157),\n",
       " ('impotenza', 0.6199026703834534),\n",
       " ('lovecraft', 0.6192747950553894),\n",
       " ('oppressione', 0.6156490445137024)]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v13.wv.most_similar(positive=['terrore'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "80953244",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v13.save(os.path.join('../trained_models/Word2Vec0', 'w2v13.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02105e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
